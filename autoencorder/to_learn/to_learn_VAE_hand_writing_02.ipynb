{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aidiary.hatenablog.com/entry/20180228/1519828344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "seed = 1\n",
    "out_dir = './vae_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is selected as device!\n"
     ]
    }
   ],
   "source": [
    "def select_device():\n",
    "    # “”\"GPU もしくは CPU の選択“”\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda is selected as device!')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        print('mps is selected as device!')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('cpu....f')\n",
    "    return device\n",
    "cuda = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',\n",
    "                   train=False,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc21 = nn.Linear(512, 2)  # mu\n",
    "        self.fc22 = nn.Linear(512, 2)  # logvar\n",
    "\n",
    "        self.fc3 = nn.Linear(2, 512)\n",
    "        self.fc4 = nn.Linear(512, 784)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        return self.fc21(h), self.fc22(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "model = VAE()\n",
    "# if cuda:\n",
    "#     model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # size_average=Falseなのでバッチ内のサンプルの合計lossを求める\n",
    "    # reconstruction loss 入力画像をどのくらい正確に復元できたか？\n",
    "    # 数式では対数尤度の最大化だが交差エントロピーlossの最小化と等価\n",
    "    recon = F.binary_cross_entropy(recon_x, x.view(-1, 784), size_average=False)\n",
    "\n",
    "    # 潜在空間zに対する正則化項\n",
    "    # P(z|x) が N(0, I)に近くなる（KL-distanceが小さくなる）ようにする\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return recon + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m test_loss_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     loss \u001b[39m=\u001b[39m train(epoch)\n\u001b[1;32m     45\u001b[0m     test_loss \u001b[39m=\u001b[39m test(epoch)\n\u001b[1;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m test_loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     48\u001b[0m         epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     49\u001b[0m         num_epochs,\n\u001b[1;32m     50\u001b[0m         loss,\n\u001b[1;32m     51\u001b[0m         test_loss))\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(recon_batch, data, mu, logvar)\n\u001b[1;32m      9\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 10\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mdata[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[39m# loss_function() は平均ではなく全サンプルの合計lossを返すのでサンプル数で割る\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss_function() は平均ではなく全サンプルの合計lossを返すのでサンプル数で割る\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    return train_loss    \n",
    "    \n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        test_loss += loss.data[0]\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # 10エポックごとに最初のminibatchの入力画像と復元画像を保存\n",
    "            if batch_idx == 0:\n",
    "                n = 8\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.data.cpu(),\n",
    "                           '{}/reconstruction_{}.png'.format(out_dir, epoch), nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "\n",
    "    print('epoch [{}/{}], loss: {:.4f} test_loss: {:.4f}'.format(\n",
    "        epoch + 1,\n",
    "        num_epochs,\n",
    "        loss,\n",
    "        test_loss))\n",
    "\n",
    "    # logging\n",
    "    loss_list.append(loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "\n",
    "# save the training model\n",
    "np.save('loss_list.npy', np.array(loss_list))\n",
    "np.save('test_loss_list.npy', np.array(test_loss_list))\n",
    "torch.save(model.state_dict(), 'vae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7b63737d34f860a632a8143e822850a892e75196c8e7207c138f17d21e5a1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
