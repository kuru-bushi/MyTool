{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE について学習\n",
    "- https://data-analytics.fun/2022/01/22/pytorch-vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "# PyTorch画像用\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "# 画像表示用\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1df22baa594f378443f705f7d61304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6016fa9f383c42738dd180cfe7f6785e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a22c5f8a8f54584a4951bb267e4061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3a050a0a2f4dcda078a855e96501a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# データセットの取得\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    # ToTensor関数の動きを理解しnumpyと相互変換できるようになる\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "# DataLoaderの作成\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 8, 9, 4, 6, 5, 4, 3, 3, 6, 8, 8, 5, 2, 3, 0, 0, 0, 5, 6, 7, 9, 7, 6,\n",
      "        0, 4, 1, 0, 2, 9, 3, 0, 4, 6, 2, 8, 3, 4, 1, 0, 6, 6, 8, 1, 4, 6, 4, 9,\n",
      "        0, 5, 6, 0, 8, 8, 7, 6, 2, 6, 7, 2, 8, 3, 4, 7, 5, 8, 8, 0, 6, 3, 9, 6,\n",
      "        3, 2, 5, 1, 3, 4, 6, 7, 5, 6, 1, 7, 5, 4, 0, 3, 0, 6, 3, 2, 5, 3, 0, 8,\n",
      "        2, 4, 8, 9, 2, 8, 4, 0, 6, 9, 0, 4, 1, 4, 7, 4, 1, 3, 9, 8, 1, 1, 1, 4,\n",
      "        3, 1, 1, 5, 9, 4, 2, 1])]\n"
     ]
    }
   ],
   "source": [
    "for test in train_loader:\n",
    "    print(test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "    super(Encoder, self).__init__()\n",
    "    # PyTorch で全結合層を定義 線形結合\n",
    "    self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "    self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "    self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # ニューラルネットワークで事後分布の平均・分散を計算する\n",
    "    h = torch.relu(self.fc(x))\n",
    "    mu = self.fc_mu(h) # μ\n",
    "    log_var = self.fc_var(h) # log σ^2\n",
    " \n",
    "    # 潜在変数を求める\n",
    "    ## 標準正規乱数を振る\n",
    "    # 平均 0、分散 1 の正規分布からの乱数で満たさ れたものと同じサイズのテンソルを返します\n",
    "    eps = torch.randn_like(torch.exp(log_var))\n",
    "    ## 潜在変数の計算 μ + σ・ε\n",
    "    z = mu + torch.exp(log_var / 2) * eps\n",
    "    return mu, log_var, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.fc = nn.Linear(latent_dim, hidden_dim)\n",
    "    self.fc_output = nn.Linear(hidden_dim, input_dim)\n",
    "  \n",
    "  def forward(self, z):\n",
    "      h = torch.relu(self.fc(z))\n",
    "      # 最後の全結合層の活性化関数はシグモイド関数として、0~1の値を返します。\n",
    "      output = torch.sigmoid(self.fc_output(h))\n",
    "      return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "    super(VAE, self).__init__()\n",
    "    self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "    self.decoder = Decoder(input_dim, hidden_dim, latent_dim)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    mu, log_var, z = self.encoder(x) # エンコード\n",
    "    x_decoded = self.decoder(z) # デコード\n",
    "    return x_decoded, mu, log_var, z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(label, predict, mu, log_var):\n",
    "  reconstruction_loss = F.binary_cross_entropy(predict, label, reduction='sum')\n",
    "  # KLダイバージェンス項の計算\n",
    "  kl_loss = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "  vae_loss = reconstruction_loss + kl_loss\n",
    "  return vae_loss, reconstruction_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is selected as device!\n"
     ]
    }
   ],
   "source": [
    "# 長田さんコード\n",
    "def select_device():\n",
    "    # “”\"GPU もしくは CPU の選択“”\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda is selected as device!')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        print('mps is selected as device!')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('cpu....f')\n",
    "    return device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 * 28\n",
    "h_dim = 32\n",
    "z_dim = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    " \n",
    "model = VAE(image_size, h_dim, z_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss:  68246.7891, reconstruct loss:  68137.4922, KL loss:  109.2957\n",
      "Epoch: 1, loss:  64762.3125, reconstruct loss:  64583.4023, KL loss:  178.9115\n",
      "Epoch: 1, loss:  57676.3398, reconstruct loss:  56387.1172, KL loss:  1289.2239\n",
      "Epoch: 1, loss:  47143.0625, reconstruct loss:  43229.8711, KL loss:  3913.1904\n",
      "Epoch: 1, loss:  38560.1641, reconstruct loss:  34318.4805, KL loss:  4241.6846\n",
      "Epoch: 1, loss:  34368.0586, reconstruct loss:  31318.9414, KL loss:  3049.1182\n",
      "Epoch: 1, loss:  31968.4199, reconstruct loss:  29278.2227, KL loss:  2690.1968\n",
      "Epoch: 1, loss:  31524.9258, reconstruct loss:  29040.0234, KL loss:  2484.9033\n",
      "Epoch: 1, loss:  30196.3828, reconstruct loss:  27966.3359, KL loss:  2230.0474\n",
      "Epoch: 1, loss:  29937.6621, reconstruct loss:  28023.0859, KL loss:  1914.5769\n",
      "Epoch: 1, loss:  29682.1348, reconstruct loss:  27814.4668, KL loss:  1867.6685\n",
      "Epoch: 1, loss:  29084.5820, reconstruct loss:  27289.1230, KL loss:  1795.4596\n",
      "Epoch: 1, loss:  28992.4805, reconstruct loss:  27056.8555, KL loss:  1935.6245\n",
      "Epoch: 1, loss:  29332.1113, reconstruct loss:  27734.3223, KL loss:  1597.7883\n",
      "Epoch: 1, loss:  28437.9219, reconstruct loss:  26897.0645, KL loss:  1540.8569\n",
      "Epoch: 1, loss:  26893.2637, reconstruct loss:  25187.5039, KL loss:  1705.7594\n",
      "Epoch: 1, loss:  28221.4883, reconstruct loss:  26700.3320, KL loss:  1521.1565\n",
      "Epoch: 1, loss:  28038.2988, reconstruct loss:  26574.3164, KL loss:  1463.9824\n",
      "Epoch: 1, loss:  27032.2773, reconstruct loss:  25530.3398, KL loss:  1501.9379\n",
      "Epoch: 1, loss:  26700.6367, reconstruct loss:  25238.2930, KL loss:  1462.3438\n",
      "Epoch: 1, loss:  26517.0332, reconstruct loss:  25053.6465, KL loss:  1463.3864\n",
      "Epoch: 1, loss:  27597.1660, reconstruct loss:  26050.2734, KL loss:  1546.8926\n",
      "Epoch: 1, loss:  24948.8652, reconstruct loss:  23188.8789, KL loss:  1759.9869\n",
      "Epoch: 1, loss:  25029.4121, reconstruct loss:  23581.3203, KL loss:  1448.0918\n",
      "Epoch: 1, loss:  25546.6016, reconstruct loss:  24082.9297, KL loss:  1463.6729\n",
      "Epoch: 1, loss:  26311.3281, reconstruct loss:  24729.1562, KL loss:  1582.1724\n",
      "Epoch: 1, loss:  25897.4219, reconstruct loss:  24219.5996, KL loss:  1677.8223\n",
      "Epoch: 1, loss:  24821.5566, reconstruct loss:  23326.0625, KL loss:  1495.4934\n",
      "Epoch: 1, loss:  24987.0156, reconstruct loss:  23495.7266, KL loss:  1491.2893\n",
      "Epoch: 1, loss:  24780.9824, reconstruct loss:  23333.5469, KL loss:  1447.4362\n",
      "Epoch: 1, loss:  24846.0605, reconstruct loss:  23411.4180, KL loss:  1434.6426\n",
      "Epoch: 1, loss:  24852.0215, reconstruct loss:  23356.9453, KL loss:  1495.0753\n",
      "Epoch: 1, loss:  24417.4121, reconstruct loss:  22878.4980, KL loss:  1538.9147\n",
      "Epoch: 1, loss:  23802.9551, reconstruct loss:  22268.1074, KL loss:  1534.8474\n",
      "Epoch: 1, loss:  24678.0254, reconstruct loss:  23210.1797, KL loss:  1467.8452\n",
      "Epoch: 1, loss:  24098.0098, reconstruct loss:  22510.6426, KL loss:  1587.3674\n",
      "Epoch: 1, loss:  23437.4336, reconstruct loss:  21725.0078, KL loss:  1712.4255\n",
      "Epoch: 1, loss:  23670.4102, reconstruct loss:  22025.4023, KL loss:  1645.0077\n",
      "Epoch: 1, loss:  23693.5938, reconstruct loss:  21988.0469, KL loss:  1705.5469\n",
      "Epoch: 1, loss:  24007.6250, reconstruct loss:  22308.6777, KL loss:  1698.9463\n",
      "Epoch: 1, loss:  22239.0000, reconstruct loss:  20492.6992, KL loss:  1746.3005\n",
      "Epoch: 1, loss:  23668.4355, reconstruct loss:  21974.2500, KL loss:  1694.1863\n",
      "Epoch: 1, loss:  23010.3047, reconstruct loss:  21303.4863, KL loss:  1706.8176\n",
      "Epoch: 1, loss:  22551.0645, reconstruct loss:  20766.6621, KL loss:  1784.4027\n",
      "Epoch: 1, loss:  22724.8457, reconstruct loss:  21039.4219, KL loss:  1685.4236\n",
      "Epoch: 1, loss:  23426.8340, reconstruct loss:  21673.5977, KL loss:  1753.2369\n",
      "Epoch: 2, loss:  23282.0742, reconstruct loss:  21440.5078, KL loss:  1841.5662\n",
      "Epoch: 2, loss:  23629.0430, reconstruct loss:  21911.6914, KL loss:  1717.3508\n",
      "Epoch: 2, loss:  23188.5723, reconstruct loss:  21488.5254, KL loss:  1700.0471\n",
      "Epoch: 2, loss:  23057.5859, reconstruct loss:  21292.9141, KL loss:  1764.6711\n",
      "Epoch: 2, loss:  22539.6680, reconstruct loss:  20789.1602, KL loss:  1750.5068\n",
      "Epoch: 2, loss:  22665.0195, reconstruct loss:  21033.8789, KL loss:  1631.1407\n",
      "Epoch: 2, loss:  22261.1367, reconstruct loss:  20608.3711, KL loss:  1652.7664\n",
      "Epoch: 2, loss:  22851.4199, reconstruct loss:  21098.3125, KL loss:  1753.1079\n",
      "Epoch: 2, loss:  22034.5605, reconstruct loss:  20407.9453, KL loss:  1626.6145\n",
      "Epoch: 2, loss:  21492.5762, reconstruct loss:  19790.1641, KL loss:  1702.4119\n",
      "Epoch: 2, loss:  22197.6934, reconstruct loss:  20522.4023, KL loss:  1675.2908\n",
      "Epoch: 2, loss:  21520.8535, reconstruct loss:  19813.6172, KL loss:  1707.2366\n",
      "Epoch: 2, loss:  22252.2559, reconstruct loss:  20557.6367, KL loss:  1694.6190\n",
      "Epoch: 2, loss:  22670.4551, reconstruct loss:  20903.7969, KL loss:  1766.6580\n",
      "Epoch: 2, loss:  22214.8438, reconstruct loss:  20396.9238, KL loss:  1817.9196\n",
      "Epoch: 2, loss:  21201.0742, reconstruct loss:  19529.1094, KL loss:  1671.9645\n",
      "Epoch: 2, loss:  22441.1738, reconstruct loss:  20767.2891, KL loss:  1673.8848\n",
      "Epoch: 2, loss:  21771.4219, reconstruct loss:  20114.0430, KL loss:  1657.3794\n",
      "Epoch: 2, loss:  22179.3398, reconstruct loss:  20545.1289, KL loss:  1634.2102\n",
      "Epoch: 2, loss:  22296.7715, reconstruct loss:  20588.4219, KL loss:  1708.3489\n",
      "Epoch: 2, loss:  22047.1074, reconstruct loss:  20415.9199, KL loss:  1631.1881\n",
      "Epoch: 2, loss:  21347.5488, reconstruct loss:  19736.7656, KL loss:  1610.7827\n",
      "Epoch: 2, loss:  21441.8750, reconstruct loss:  19731.4082, KL loss:  1710.4658\n",
      "Epoch: 2, loss:  21146.6348, reconstruct loss:  19470.0352, KL loss:  1676.6005\n",
      "Epoch: 2, loss:  21437.2109, reconstruct loss:  19769.1152, KL loss:  1668.0957\n",
      "Epoch: 2, loss:  21729.7324, reconstruct loss:  20082.4766, KL loss:  1647.2554\n",
      "Epoch: 2, loss:  21584.4922, reconstruct loss:  19821.8242, KL loss:  1762.6685\n",
      "Epoch: 2, loss:  21473.5391, reconstruct loss:  19732.9922, KL loss:  1740.5466\n",
      "Epoch: 2, loss:  22056.9590, reconstruct loss:  20310.3594, KL loss:  1746.5991\n",
      "Epoch: 2, loss:  20521.9023, reconstruct loss:  18736.6328, KL loss:  1785.2693\n",
      "Epoch: 2, loss:  21515.8535, reconstruct loss:  19665.6270, KL loss:  1850.2267\n",
      "Epoch: 2, loss:  21055.6133, reconstruct loss:  19299.8867, KL loss:  1755.7266\n",
      "Epoch: 2, loss:  20915.5059, reconstruct loss:  19108.2637, KL loss:  1807.2417\n",
      "Epoch: 2, loss:  21450.4766, reconstruct loss:  19735.6719, KL loss:  1714.8040\n",
      "Epoch: 2, loss:  20357.8945, reconstruct loss:  18555.6016, KL loss:  1802.2926\n",
      "Epoch: 2, loss:  20102.0098, reconstruct loss:  18327.4180, KL loss:  1774.5924\n",
      "Epoch: 2, loss:  20589.5898, reconstruct loss:  18686.1836, KL loss:  1903.4056\n",
      "Epoch: 2, loss:  21300.9355, reconstruct loss:  19470.6387, KL loss:  1830.2971\n",
      "Epoch: 2, loss:  20505.9219, reconstruct loss:  18637.8281, KL loss:  1868.0928\n",
      "Epoch: 2, loss:  20684.8164, reconstruct loss:  18874.2832, KL loss:  1810.5332\n",
      "Epoch: 2, loss:  20464.6152, reconstruct loss:  18651.1523, KL loss:  1813.4622\n",
      "Epoch: 2, loss:  20062.3828, reconstruct loss:  18263.2598, KL loss:  1799.1221\n",
      "Epoch: 2, loss:  20380.8535, reconstruct loss:  18540.1797, KL loss:  1840.6738\n",
      "Epoch: 2, loss:  19537.9258, reconstruct loss:  17721.7305, KL loss:  1816.1948\n",
      "Epoch: 2, loss:  20630.7383, reconstruct loss:  18729.3438, KL loss:  1901.3938\n",
      "Epoch: 2, loss:  20472.3379, reconstruct loss:  18684.7988, KL loss:  1787.5396\n",
      "Epoch: 3, loss:  20385.3809, reconstruct loss:  18504.0977, KL loss:  1881.2841\n",
      "Epoch: 3, loss:  19803.3398, reconstruct loss:  17915.8398, KL loss:  1887.5005\n",
      "Epoch: 3, loss:  20095.5352, reconstruct loss:  18288.7891, KL loss:  1806.7454\n",
      "Epoch: 3, loss:  20379.3398, reconstruct loss:  18410.1855, KL loss:  1969.1548\n",
      "Epoch: 3, loss:  20508.6680, reconstruct loss:  18541.1914, KL loss:  1967.4772\n",
      "Epoch: 3, loss:  20806.8750, reconstruct loss:  18905.3945, KL loss:  1901.4814\n",
      "Epoch: 3, loss:  20076.4434, reconstruct loss:  18234.7207, KL loss:  1841.7231\n",
      "Epoch: 3, loss:  20115.3398, reconstruct loss:  18234.4668, KL loss:  1880.8730\n",
      "Epoch: 3, loss:  20789.1445, reconstruct loss:  18865.4414, KL loss:  1923.7025\n",
      "Epoch: 3, loss:  19940.4844, reconstruct loss:  17922.2852, KL loss:  2018.2002\n",
      "Epoch: 3, loss:  19443.5918, reconstruct loss:  17496.8320, KL loss:  1946.7596\n",
      "Epoch: 3, loss:  20358.6484, reconstruct loss:  18509.1289, KL loss:  1849.5199\n",
      "Epoch: 3, loss:  19564.6133, reconstruct loss:  17561.3320, KL loss:  2003.2817\n",
      "Epoch: 3, loss:  19925.1777, reconstruct loss:  18009.6680, KL loss:  1915.5103\n",
      "Epoch: 3, loss:  19982.1836, reconstruct loss:  18016.6953, KL loss:  1965.4885\n",
      "Epoch: 3, loss:  20173.0547, reconstruct loss:  18205.5156, KL loss:  1967.5381\n",
      "Epoch: 3, loss:  20210.3535, reconstruct loss:  18233.9785, KL loss:  1976.3743\n",
      "Epoch: 3, loss:  19490.0488, reconstruct loss:  17582.2949, KL loss:  1907.7533\n",
      "Epoch: 3, loss:  18988.1465, reconstruct loss:  17120.2324, KL loss:  1867.9148\n",
      "Epoch: 3, loss:  19989.9883, reconstruct loss:  18057.8633, KL loss:  1932.1252\n",
      "Epoch: 3, loss:  19735.3516, reconstruct loss:  17829.2344, KL loss:  1906.1179\n",
      "Epoch: 3, loss:  19449.6016, reconstruct loss:  17466.1035, KL loss:  1983.4977\n",
      "Epoch: 3, loss:  19710.2148, reconstruct loss:  17704.2812, KL loss:  2005.9326\n",
      "Epoch: 3, loss:  19709.2461, reconstruct loss:  17772.1855, KL loss:  1937.0602\n",
      "Epoch: 3, loss:  20663.7754, reconstruct loss:  18719.9102, KL loss:  1943.8647\n",
      "Epoch: 3, loss:  19328.2285, reconstruct loss:  17413.6699, KL loss:  1914.5579\n",
      "Epoch: 3, loss:  19546.4277, reconstruct loss:  17600.9961, KL loss:  1945.4320\n",
      "Epoch: 3, loss:  19406.6348, reconstruct loss:  17469.3066, KL loss:  1937.3274\n",
      "Epoch: 3, loss:  20330.8066, reconstruct loss:  18415.7539, KL loss:  1915.0535\n",
      "Epoch: 3, loss:  19126.5605, reconstruct loss:  17197.8984, KL loss:  1928.6625\n",
      "Epoch: 3, loss:  19492.1250, reconstruct loss:  17563.7070, KL loss:  1928.4172\n",
      "Epoch: 3, loss:  19557.8672, reconstruct loss:  17641.7930, KL loss:  1916.0746\n",
      "Epoch: 3, loss:  19593.4316, reconstruct loss:  17582.8633, KL loss:  2010.5680\n",
      "Epoch: 3, loss:  19078.4844, reconstruct loss:  17019.5918, KL loss:  2058.8921\n",
      "Epoch: 3, loss:  19511.3770, reconstruct loss:  17525.0078, KL loss:  1986.3683\n",
      "Epoch: 3, loss:  19091.0234, reconstruct loss:  17051.1035, KL loss:  2039.9198\n",
      "Epoch: 3, loss:  20096.2441, reconstruct loss:  18127.1191, KL loss:  1969.1256\n",
      "Epoch: 3, loss:  18465.7598, reconstruct loss:  16567.5000, KL loss:  1898.2605\n",
      "Epoch: 3, loss:  19300.8340, reconstruct loss:  17348.0898, KL loss:  1952.7437\n",
      "Epoch: 3, loss:  18896.9941, reconstruct loss:  16873.1367, KL loss:  2023.8579\n",
      "Epoch: 3, loss:  19510.0273, reconstruct loss:  17526.7578, KL loss:  1983.2705\n",
      "Epoch: 3, loss:  18765.9746, reconstruct loss:  16845.5039, KL loss:  1920.4706\n",
      "Epoch: 3, loss:  19401.2070, reconstruct loss:  17410.5801, KL loss:  1990.6263\n",
      "Epoch: 3, loss:  19087.6914, reconstruct loss:  17104.4727, KL loss:  1983.2188\n",
      "Epoch: 3, loss:  19138.3008, reconstruct loss:  17099.0723, KL loss:  2039.2295\n",
      "Epoch: 3, loss:  19099.8418, reconstruct loss:  17088.9082, KL loss:  2010.9329\n",
      "Epoch: 4, loss:  18618.5586, reconstruct loss:  16709.7656, KL loss:  1908.7925\n",
      "Epoch: 4, loss:  18688.4395, reconstruct loss:  16661.5586, KL loss:  2026.8804\n",
      "Epoch: 4, loss:  18860.7695, reconstruct loss:  16881.2637, KL loss:  1979.5054\n",
      "Epoch: 4, loss:  18689.3418, reconstruct loss:  16647.5547, KL loss:  2041.7865\n",
      "Epoch: 4, loss:  19050.6211, reconstruct loss:  17078.5195, KL loss:  1972.1014\n",
      "Epoch: 4, loss:  19023.2988, reconstruct loss:  17000.6230, KL loss:  2022.6752\n",
      "Epoch: 4, loss:  19883.3945, reconstruct loss:  17894.0391, KL loss:  1989.3551\n",
      "Epoch: 4, loss:  18499.4824, reconstruct loss:  16538.9219, KL loss:  1960.5608\n",
      "Epoch: 4, loss:  19435.1484, reconstruct loss:  17479.4824, KL loss:  1955.6663\n",
      "Epoch: 4, loss:  18564.2539, reconstruct loss:  16514.3672, KL loss:  2049.8857\n",
      "Epoch: 4, loss:  18848.9688, reconstruct loss:  16939.1562, KL loss:  1909.8126\n",
      "Epoch: 4, loss:  18543.4629, reconstruct loss:  16482.1055, KL loss:  2061.3574\n",
      "Epoch: 4, loss:  19013.3027, reconstruct loss:  16949.6016, KL loss:  2063.7012\n",
      "Epoch: 4, loss:  19709.6211, reconstruct loss:  17718.0449, KL loss:  1991.5759\n",
      "Epoch: 4, loss:  18908.5156, reconstruct loss:  16852.8184, KL loss:  2055.6973\n",
      "Epoch: 4, loss:  18924.5723, reconstruct loss:  16913.2227, KL loss:  2011.3494\n",
      "Epoch: 4, loss:  19277.4590, reconstruct loss:  17359.6367, KL loss:  1917.8230\n",
      "Epoch: 4, loss:  18673.1113, reconstruct loss:  16561.4531, KL loss:  2111.6584\n",
      "Epoch: 4, loss:  19263.8887, reconstruct loss:  17200.9062, KL loss:  2062.9824\n",
      "Epoch: 4, loss:  18364.9453, reconstruct loss:  16366.1523, KL loss:  1998.7932\n",
      "Epoch: 4, loss:  18414.4531, reconstruct loss:  16430.3359, KL loss:  1984.1180\n",
      "Epoch: 4, loss:  19318.7266, reconstruct loss:  17356.6504, KL loss:  1962.0764\n",
      "Epoch: 4, loss:  18793.6055, reconstruct loss:  16781.5000, KL loss:  2012.1046\n",
      "Epoch: 4, loss:  18138.8535, reconstruct loss:  16095.6045, KL loss:  2043.2493\n",
      "Epoch: 4, loss:  19657.3906, reconstruct loss:  17671.4746, KL loss:  1985.9154\n",
      "Epoch: 4, loss:  18447.1660, reconstruct loss:  16393.7266, KL loss:  2053.4399\n",
      "Epoch: 4, loss:  19134.2715, reconstruct loss:  17132.9590, KL loss:  2001.3123\n",
      "Epoch: 4, loss:  18219.8633, reconstruct loss:  16111.3066, KL loss:  2108.5559\n",
      "Epoch: 4, loss:  18259.5000, reconstruct loss:  16257.8789, KL loss:  2001.6221\n",
      "Epoch: 4, loss:  18336.3125, reconstruct loss:  16261.5703, KL loss:  2074.7424\n",
      "Epoch: 4, loss:  17728.9316, reconstruct loss:  15679.5459, KL loss:  2049.3857\n",
      "Epoch: 4, loss:  18083.3555, reconstruct loss:  16067.3965, KL loss:  2015.9592\n",
      "Epoch: 4, loss:  17587.8555, reconstruct loss:  15567.2676, KL loss:  2020.5875\n",
      "Epoch: 4, loss:  17932.3887, reconstruct loss:  15934.5830, KL loss:  1997.8065\n",
      "Epoch: 4, loss:  18626.5879, reconstruct loss:  16585.7734, KL loss:  2040.8153\n",
      "Epoch: 4, loss:  18148.6582, reconstruct loss:  16238.7520, KL loss:  1909.9054\n",
      "Epoch: 4, loss:  18871.0566, reconstruct loss:  16833.9023, KL loss:  2037.1541\n",
      "Epoch: 4, loss:  18161.6348, reconstruct loss:  16109.3945, KL loss:  2052.2400\n",
      "Epoch: 4, loss:  18343.1094, reconstruct loss:  16280.1650, KL loss:  2062.9441\n",
      "Epoch: 4, loss:  18147.7656, reconstruct loss:  16143.7109, KL loss:  2004.0542\n",
      "Epoch: 4, loss:  18582.9648, reconstruct loss:  16548.5605, KL loss:  2034.4039\n",
      "Epoch: 4, loss:  18887.1270, reconstruct loss:  16814.6309, KL loss:  2072.4966\n",
      "Epoch: 4, loss:  17619.3652, reconstruct loss:  15663.3066, KL loss:  1956.0594\n",
      "Epoch: 4, loss:  18861.4082, reconstruct loss:  16763.9551, KL loss:  2097.4539\n",
      "Epoch: 4, loss:  18382.0234, reconstruct loss:  16291.6201, KL loss:  2090.4036\n",
      "Epoch: 4, loss:  18373.3633, reconstruct loss:  16288.8145, KL loss:  2084.5486\n",
      "Epoch: 5, loss:  18575.1445, reconstruct loss:  16502.9805, KL loss:  2072.1636\n",
      "Epoch: 5, loss:  19287.3770, reconstruct loss:  17184.4727, KL loss:  2102.9048\n",
      "Epoch: 5, loss:  18376.8359, reconstruct loss:  16323.8887, KL loss:  2052.9470\n",
      "Epoch: 5, loss:  18777.6738, reconstruct loss:  16645.6914, KL loss:  2131.9829\n",
      "Epoch: 5, loss:  18860.3320, reconstruct loss:  16776.4258, KL loss:  2083.9072\n",
      "Epoch: 5, loss:  18214.6406, reconstruct loss:  16156.9814, KL loss:  2057.6587\n",
      "Epoch: 5, loss:  18831.8730, reconstruct loss:  16723.8984, KL loss:  2107.9749\n",
      "Epoch: 5, loss:  18245.9004, reconstruct loss:  16205.9355, KL loss:  2039.9656\n",
      "Epoch: 5, loss:  18230.5469, reconstruct loss:  16153.8848, KL loss:  2076.6626\n",
      "Epoch: 5, loss:  17657.8633, reconstruct loss:  15533.3184, KL loss:  2124.5444\n",
      "Epoch: 5, loss:  17882.7676, reconstruct loss:  15791.2822, KL loss:  2091.4851\n",
      "Epoch: 5, loss:  17967.3867, reconstruct loss:  15888.8623, KL loss:  2078.5244\n",
      "Epoch: 5, loss:  19187.3184, reconstruct loss:  17077.4961, KL loss:  2109.8228\n",
      "Epoch: 5, loss:  17772.1953, reconstruct loss:  15778.1855, KL loss:  1994.0096\n",
      "Epoch: 5, loss:  17944.0234, reconstruct loss:  15839.2266, KL loss:  2104.7959\n",
      "Epoch: 5, loss:  17961.2383, reconstruct loss:  15853.1680, KL loss:  2108.0703\n",
      "Epoch: 5, loss:  17663.8320, reconstruct loss:  15604.2441, KL loss:  2059.5874\n",
      "Epoch: 5, loss:  18161.9492, reconstruct loss:  16096.0420, KL loss:  2065.9080\n",
      "Epoch: 5, loss:  18517.3223, reconstruct loss:  16459.3594, KL loss:  2057.9631\n",
      "Epoch: 5, loss:  18374.9941, reconstruct loss:  16292.6406, KL loss:  2082.3540\n",
      "Epoch: 5, loss:  17624.0996, reconstruct loss:  15533.6250, KL loss:  2090.4746\n",
      "Epoch: 5, loss:  18168.4473, reconstruct loss:  16039.7539, KL loss:  2128.6929\n",
      "Epoch: 5, loss:  18251.3359, reconstruct loss:  16176.4414, KL loss:  2074.8955\n",
      "Epoch: 5, loss:  17339.1562, reconstruct loss:  15266.9521, KL loss:  2072.2041\n",
      "Epoch: 5, loss:  18518.0664, reconstruct loss:  16468.1367, KL loss:  2049.9302\n",
      "Epoch: 5, loss:  17758.6016, reconstruct loss:  15765.5811, KL loss:  1993.0209\n",
      "Epoch: 5, loss:  17861.0293, reconstruct loss:  15760.1016, KL loss:  2100.9277\n",
      "Epoch: 5, loss:  18210.7949, reconstruct loss:  16097.8281, KL loss:  2112.9673\n",
      "Epoch: 5, loss:  18235.3477, reconstruct loss:  16125.0371, KL loss:  2110.3110\n",
      "Epoch: 5, loss:  17915.5605, reconstruct loss:  15900.3271, KL loss:  2015.2341\n",
      "Epoch: 5, loss:  17868.7617, reconstruct loss:  15807.6631, KL loss:  2061.0977\n",
      "Epoch: 5, loss:  18062.7734, reconstruct loss:  15971.5264, KL loss:  2091.2471\n",
      "Epoch: 5, loss:  17920.3750, reconstruct loss:  15788.2988, KL loss:  2132.0762\n",
      "Epoch: 5, loss:  18118.3965, reconstruct loss:  16098.5469, KL loss:  2019.8495\n",
      "Epoch: 5, loss:  18061.7383, reconstruct loss:  15991.9385, KL loss:  2069.7998\n",
      "Epoch: 5, loss:  17647.1875, reconstruct loss:  15579.6416, KL loss:  2067.5452\n",
      "Epoch: 5, loss:  17572.6562, reconstruct loss:  15526.4766, KL loss:  2046.1787\n",
      "Epoch: 5, loss:  17752.2031, reconstruct loss:  15615.3779, KL loss:  2136.8250\n",
      "Epoch: 5, loss:  18001.3516, reconstruct loss:  15920.9336, KL loss:  2080.4182\n",
      "Epoch: 5, loss:  17887.9355, reconstruct loss:  15752.0879, KL loss:  2135.8477\n",
      "Epoch: 5, loss:  18374.6836, reconstruct loss:  16294.2285, KL loss:  2080.4556\n",
      "Epoch: 5, loss:  18044.8906, reconstruct loss:  15964.7207, KL loss:  2080.1709\n",
      "Epoch: 5, loss:  17819.9023, reconstruct loss:  15770.5312, KL loss:  2049.3711\n",
      "Epoch: 5, loss:  18045.7129, reconstruct loss:  15983.0176, KL loss:  2062.6960\n",
      "Epoch: 5, loss:  18184.2695, reconstruct loss:  16065.8867, KL loss:  2118.3831\n",
      "Epoch: 5, loss:  17658.5898, reconstruct loss:  15548.3252, KL loss:  2110.2656\n",
      "Epoch: 6, loss:  17825.1660, reconstruct loss:  15705.4648, KL loss:  2119.7004\n",
      "Epoch: 6, loss:  18181.1016, reconstruct loss:  16104.2129, KL loss:  2076.8894\n",
      "Epoch: 6, loss:  17906.2129, reconstruct loss:  15773.5918, KL loss:  2132.6218\n",
      "Epoch: 6, loss:  18243.6289, reconstruct loss:  16068.6348, KL loss:  2174.9941\n",
      "Epoch: 6, loss:  17403.1758, reconstruct loss:  15298.1484, KL loss:  2105.0276\n",
      "Epoch: 6, loss:  17821.6289, reconstruct loss:  15723.8730, KL loss:  2097.7568\n",
      "Epoch: 6, loss:  17935.5391, reconstruct loss:  15794.5312, KL loss:  2141.0085\n",
      "Epoch: 6, loss:  17192.6992, reconstruct loss:  15050.0938, KL loss:  2142.6060\n",
      "Epoch: 6, loss:  17058.9258, reconstruct loss:  14925.4541, KL loss:  2133.4709\n",
      "Epoch: 6, loss:  17747.6758, reconstruct loss:  15691.5752, KL loss:  2056.1011\n",
      "Epoch: 6, loss:  18235.0645, reconstruct loss:  16083.9336, KL loss:  2151.1313\n",
      "Epoch: 6, loss:  17672.9082, reconstruct loss:  15527.4648, KL loss:  2145.4429\n",
      "Epoch: 6, loss:  17592.3770, reconstruct loss:  15510.9453, KL loss:  2081.4321\n",
      "Epoch: 6, loss:  18071.2383, reconstruct loss:  15883.6133, KL loss:  2187.6257\n",
      "Epoch: 6, loss:  18523.9805, reconstruct loss:  16338.9453, KL loss:  2185.0349\n",
      "Epoch: 6, loss:  17578.7695, reconstruct loss:  15448.4043, KL loss:  2130.3643\n",
      "Epoch: 6, loss:  17141.3691, reconstruct loss:  15026.0586, KL loss:  2115.3108\n",
      "Epoch: 6, loss:  17779.4375, reconstruct loss:  15662.8301, KL loss:  2116.6084\n",
      "Epoch: 6, loss:  17544.4199, reconstruct loss:  15345.0449, KL loss:  2199.3750\n",
      "Epoch: 6, loss:  18013.8477, reconstruct loss:  15907.4902, KL loss:  2106.3577\n",
      "Epoch: 6, loss:  17566.0566, reconstruct loss:  15396.6211, KL loss:  2169.4355\n",
      "Epoch: 6, loss:  17435.8438, reconstruct loss:  15353.8477, KL loss:  2081.9961\n",
      "Epoch: 6, loss:  17524.4141, reconstruct loss:  15492.0312, KL loss:  2032.3818\n",
      "Epoch: 6, loss:  17359.4883, reconstruct loss:  15248.5684, KL loss:  2110.9207\n",
      "Epoch: 6, loss:  17497.6211, reconstruct loss:  15440.3242, KL loss:  2057.2964\n",
      "Epoch: 6, loss:  17310.0801, reconstruct loss:  15161.8789, KL loss:  2148.2007\n",
      "Epoch: 6, loss:  17714.5938, reconstruct loss:  15500.4502, KL loss:  2214.1440\n",
      "Epoch: 6, loss:  16943.2500, reconstruct loss:  14876.7715, KL loss:  2066.4795\n",
      "Epoch: 6, loss:  17471.7598, reconstruct loss:  15325.1113, KL loss:  2146.6492\n",
      "Epoch: 6, loss:  17342.0020, reconstruct loss:  15203.3672, KL loss:  2138.6343\n",
      "Epoch: 6, loss:  17743.4590, reconstruct loss:  15661.8672, KL loss:  2081.5918\n",
      "Epoch: 6, loss:  17859.7891, reconstruct loss:  15675.7852, KL loss:  2184.0034\n",
      "Epoch: 6, loss:  17262.8809, reconstruct loss:  15122.3594, KL loss:  2140.5215\n",
      "Epoch: 6, loss:  17488.5977, reconstruct loss:  15390.8066, KL loss:  2097.7917\n",
      "Epoch: 6, loss:  17793.7422, reconstruct loss:  15659.7861, KL loss:  2133.9551\n",
      "Epoch: 6, loss:  17549.7832, reconstruct loss:  15376.4121, KL loss:  2173.3706\n",
      "Epoch: 6, loss:  17190.0508, reconstruct loss:  15088.9180, KL loss:  2101.1323\n",
      "Epoch: 6, loss:  16697.1328, reconstruct loss:  14565.8906, KL loss:  2131.2432\n",
      "Epoch: 6, loss:  17907.3320, reconstruct loss:  15712.5332, KL loss:  2194.7988\n",
      "Epoch: 6, loss:  17346.5840, reconstruct loss:  15250.6328, KL loss:  2095.9507\n",
      "Epoch: 6, loss:  17535.3242, reconstruct loss:  15389.7529, KL loss:  2145.5708\n",
      "Epoch: 6, loss:  17319.1562, reconstruct loss:  15159.7158, KL loss:  2159.4409\n",
      "Epoch: 6, loss:  17443.4004, reconstruct loss:  15216.3643, KL loss:  2227.0354\n",
      "Epoch: 6, loss:  17470.1055, reconstruct loss:  15378.9551, KL loss:  2091.1511\n",
      "Epoch: 6, loss:  16441.5273, reconstruct loss:  14295.5723, KL loss:  2145.9541\n",
      "Epoch: 6, loss:  17763.5469, reconstruct loss:  15566.8027, KL loss:  2196.7451\n",
      "Epoch: 7, loss:  16561.4492, reconstruct loss:  14448.2139, KL loss:  2113.2349\n",
      "Epoch: 7, loss:  16571.8105, reconstruct loss:  14504.1318, KL loss:  2067.6794\n",
      "Epoch: 7, loss:  17889.7734, reconstruct loss:  15712.4238, KL loss:  2177.3506\n",
      "Epoch: 7, loss:  16920.1797, reconstruct loss:  14765.9316, KL loss:  2154.2480\n",
      "Epoch: 7, loss:  17819.5898, reconstruct loss:  15687.2627, KL loss:  2132.3267\n",
      "Epoch: 7, loss:  17307.9980, reconstruct loss:  15174.1982, KL loss:  2133.7996\n",
      "Epoch: 7, loss:  16705.6113, reconstruct loss:  14502.9268, KL loss:  2202.6846\n",
      "Epoch: 7, loss:  16931.5020, reconstruct loss:  14768.4961, KL loss:  2163.0063\n",
      "Epoch: 7, loss:  17230.1992, reconstruct loss:  15040.7959, KL loss:  2189.4033\n",
      "Epoch: 7, loss:  16864.1699, reconstruct loss:  14705.2227, KL loss:  2158.9480\n",
      "Epoch: 7, loss:  18065.8555, reconstruct loss:  15797.0908, KL loss:  2268.7646\n",
      "Epoch: 7, loss:  17610.4785, reconstruct loss:  15471.6895, KL loss:  2138.7891\n",
      "Epoch: 7, loss:  17527.9160, reconstruct loss:  15383.3545, KL loss:  2144.5615\n",
      "Epoch: 7, loss:  17017.7070, reconstruct loss:  14767.3916, KL loss:  2250.3154\n",
      "Epoch: 7, loss:  17742.0957, reconstruct loss:  15562.2871, KL loss:  2179.8081\n",
      "Epoch: 7, loss:  17220.9629, reconstruct loss:  15037.8994, KL loss:  2183.0640\n",
      "Epoch: 7, loss:  17204.0000, reconstruct loss:  15051.6162, KL loss:  2152.3833\n",
      "Epoch: 7, loss:  17466.4785, reconstruct loss:  15272.9902, KL loss:  2193.4890\n",
      "Epoch: 7, loss:  16449.2246, reconstruct loss:  14389.3477, KL loss:  2059.8765\n",
      "Epoch: 7, loss:  17674.0469, reconstruct loss:  15528.2324, KL loss:  2145.8154\n",
      "Epoch: 7, loss:  16946.3711, reconstruct loss:  14814.2734, KL loss:  2132.0967\n",
      "Epoch: 7, loss:  17426.4375, reconstruct loss:  15258.6055, KL loss:  2167.8315\n",
      "Epoch: 7, loss:  17400.3906, reconstruct loss:  15286.0059, KL loss:  2114.3843\n",
      "Epoch: 7, loss:  17382.0371, reconstruct loss:  15171.8242, KL loss:  2210.2124\n",
      "Epoch: 7, loss:  16977.5723, reconstruct loss:  14801.6621, KL loss:  2175.9097\n",
      "Epoch: 7, loss:  17628.6406, reconstruct loss:  15480.0586, KL loss:  2148.5825\n",
      "Epoch: 7, loss:  17071.9668, reconstruct loss:  14901.2891, KL loss:  2170.6777\n",
      "Epoch: 7, loss:  16662.9746, reconstruct loss:  14484.1914, KL loss:  2178.7827\n",
      "Epoch: 7, loss:  16732.9102, reconstruct loss:  14591.3047, KL loss:  2141.6045\n",
      "Epoch: 7, loss:  16835.8906, reconstruct loss:  14664.2930, KL loss:  2171.5979\n",
      "Epoch: 7, loss:  17522.3320, reconstruct loss:  15351.5312, KL loss:  2170.8015\n",
      "Epoch: 7, loss:  16772.5176, reconstruct loss:  14561.7344, KL loss:  2210.7827\n",
      "Epoch: 7, loss:  17598.2695, reconstruct loss:  15411.4502, KL loss:  2186.8196\n",
      "Epoch: 7, loss:  17358.0020, reconstruct loss:  15236.0352, KL loss:  2121.9666\n",
      "Epoch: 7, loss:  17826.8379, reconstruct loss:  15625.6621, KL loss:  2201.1760\n",
      "Epoch: 7, loss:  17689.9551, reconstruct loss:  15458.9746, KL loss:  2230.9802\n",
      "Epoch: 7, loss:  17623.7168, reconstruct loss:  15391.0332, KL loss:  2232.6836\n",
      "Epoch: 7, loss:  16443.4844, reconstruct loss:  14282.7891, KL loss:  2160.6951\n",
      "Epoch: 7, loss:  18180.0703, reconstruct loss:  15878.4561, KL loss:  2301.6152\n",
      "Epoch: 7, loss:  16615.7949, reconstruct loss:  14446.5117, KL loss:  2169.2837\n",
      "Epoch: 7, loss:  16987.2949, reconstruct loss:  14806.6309, KL loss:  2180.6638\n",
      "Epoch: 7, loss:  18008.7305, reconstruct loss:  15793.8652, KL loss:  2214.8647\n",
      "Epoch: 7, loss:  17105.3770, reconstruct loss:  14924.6230, KL loss:  2180.7544\n",
      "Epoch: 7, loss:  16665.5039, reconstruct loss:  14550.2734, KL loss:  2115.2314\n",
      "Epoch: 7, loss:  16929.1992, reconstruct loss:  14700.7168, KL loss:  2228.4834\n",
      "Epoch: 7, loss:  16864.5547, reconstruct loss:  14661.4512, KL loss:  2203.1035\n",
      "Epoch: 8, loss:  17119.1523, reconstruct loss:  14925.8916, KL loss:  2193.2598\n",
      "Epoch: 8, loss:  16985.0195, reconstruct loss:  14726.4609, KL loss:  2258.5579\n",
      "Epoch: 8, loss:  17492.6914, reconstruct loss:  15212.9551, KL loss:  2279.7373\n",
      "Epoch: 8, loss:  17411.5703, reconstruct loss:  15160.1914, KL loss:  2251.3779\n",
      "Epoch: 8, loss:  17256.6582, reconstruct loss:  15034.4355, KL loss:  2222.2227\n",
      "Epoch: 8, loss:  16565.7559, reconstruct loss:  14454.1855, KL loss:  2111.5710\n",
      "Epoch: 8, loss:  17445.5293, reconstruct loss:  15252.9570, KL loss:  2192.5718\n",
      "Epoch: 8, loss:  17508.3555, reconstruct loss:  15312.0146, KL loss:  2196.3408\n",
      "Epoch: 8, loss:  16522.0430, reconstruct loss:  14364.7549, KL loss:  2157.2876\n",
      "Epoch: 8, loss:  16634.0254, reconstruct loss:  14402.1709, KL loss:  2231.8540\n",
      "Epoch: 8, loss:  16743.4746, reconstruct loss:  14547.7852, KL loss:  2195.6887\n",
      "Epoch: 8, loss:  16632.6016, reconstruct loss:  14431.4082, KL loss:  2201.1929\n",
      "Epoch: 8, loss:  17298.9473, reconstruct loss:  15121.0098, KL loss:  2177.9380\n",
      "Epoch: 8, loss:  17067.4512, reconstruct loss:  14882.1777, KL loss:  2185.2734\n",
      "Epoch: 8, loss:  16551.8906, reconstruct loss:  14266.6982, KL loss:  2285.1919\n",
      "Epoch: 8, loss:  16390.6523, reconstruct loss:  14162.5195, KL loss:  2228.1326\n",
      "Epoch: 8, loss:  17081.5820, reconstruct loss:  14801.7715, KL loss:  2279.8110\n",
      "Epoch: 8, loss:  16429.8555, reconstruct loss:  14287.5752, KL loss:  2142.2798\n",
      "Epoch: 8, loss:  17610.3750, reconstruct loss:  15390.3320, KL loss:  2220.0435\n",
      "Epoch: 8, loss:  16643.3594, reconstruct loss:  14439.3682, KL loss:  2203.9912\n",
      "Epoch: 8, loss:  17213.1055, reconstruct loss:  15016.3438, KL loss:  2196.7612\n",
      "Epoch: 8, loss:  16761.0176, reconstruct loss:  14510.5566, KL loss:  2250.4609\n",
      "Epoch: 8, loss:  16481.5820, reconstruct loss:  14393.0000, KL loss:  2088.5818\n",
      "Epoch: 8, loss:  16376.4531, reconstruct loss:  14209.8838, KL loss:  2166.5693\n",
      "Epoch: 8, loss:  16477.9121, reconstruct loss:  14285.5879, KL loss:  2192.3235\n",
      "Epoch: 8, loss:  17400.0449, reconstruct loss:  15148.2598, KL loss:  2251.7847\n",
      "Epoch: 8, loss:  17029.4922, reconstruct loss:  14754.6016, KL loss:  2274.8906\n",
      "Epoch: 8, loss:  16130.7178, reconstruct loss:  13957.3613, KL loss:  2173.3562\n",
      "Epoch: 8, loss:  17073.9258, reconstruct loss:  14849.6406, KL loss:  2224.2852\n",
      "Epoch: 8, loss:  16753.1973, reconstruct loss:  14503.7607, KL loss:  2249.4370\n",
      "Epoch: 8, loss:  17101.4219, reconstruct loss:  14901.1133, KL loss:  2200.3091\n",
      "Epoch: 8, loss:  16678.9688, reconstruct loss:  14444.7207, KL loss:  2234.2480\n",
      "Epoch: 8, loss:  16826.9707, reconstruct loss:  14551.3340, KL loss:  2275.6372\n",
      "Epoch: 8, loss:  16387.4688, reconstruct loss:  14148.7500, KL loss:  2238.7195\n",
      "Epoch: 8, loss:  16564.6387, reconstruct loss:  14382.2979, KL loss:  2182.3401\n",
      "Epoch: 8, loss:  17007.3516, reconstruct loss:  14800.3271, KL loss:  2207.0254\n",
      "Epoch: 8, loss:  16501.2461, reconstruct loss:  14232.4336, KL loss:  2268.8127\n",
      "Epoch: 8, loss:  17452.3320, reconstruct loss:  15176.5664, KL loss:  2275.7666\n",
      "Epoch: 8, loss:  16832.3691, reconstruct loss:  14618.8760, KL loss:  2213.4934\n",
      "Epoch: 8, loss:  16292.2031, reconstruct loss:  14075.6309, KL loss:  2216.5723\n",
      "Epoch: 8, loss:  16984.5156, reconstruct loss:  14683.8311, KL loss:  2300.6838\n",
      "Epoch: 8, loss:  17579.1074, reconstruct loss:  15358.2588, KL loss:  2220.8481\n",
      "Epoch: 8, loss:  16752.2832, reconstruct loss:  14503.2617, KL loss:  2249.0220\n",
      "Epoch: 8, loss:  16378.7930, reconstruct loss:  14125.7227, KL loss:  2253.0708\n",
      "Epoch: 8, loss:  16837.6055, reconstruct loss:  14620.2852, KL loss:  2217.3213\n",
      "Epoch: 8, loss:  16222.2705, reconstruct loss:  13993.5576, KL loss:  2228.7126\n",
      "Epoch: 9, loss:  16741.9961, reconstruct loss:  14537.5283, KL loss:  2204.4685\n",
      "Epoch: 9, loss:  17153.4805, reconstruct loss:  14963.9150, KL loss:  2189.5645\n",
      "Epoch: 9, loss:  16330.3115, reconstruct loss:  14150.1875, KL loss:  2180.1240\n",
      "Epoch: 9, loss:  16943.8652, reconstruct loss:  14748.6172, KL loss:  2195.2480\n",
      "Epoch: 9, loss:  17570.0879, reconstruct loss:  15312.1309, KL loss:  2257.9570\n",
      "Epoch: 9, loss:  16835.1719, reconstruct loss:  14577.0938, KL loss:  2258.0771\n",
      "Epoch: 9, loss:  16448.5996, reconstruct loss:  14185.4873, KL loss:  2263.1116\n",
      "Epoch: 9, loss:  15963.3359, reconstruct loss:  13814.9355, KL loss:  2148.4006\n",
      "Epoch: 9, loss:  17235.9688, reconstruct loss:  15006.2129, KL loss:  2229.7563\n",
      "Epoch: 9, loss:  16517.2695, reconstruct loss:  14371.2471, KL loss:  2146.0215\n",
      "Epoch: 9, loss:  16632.1133, reconstruct loss:  14435.6094, KL loss:  2196.5044\n",
      "Epoch: 9, loss:  16877.8262, reconstruct loss:  14642.6357, KL loss:  2235.1909\n",
      "Epoch: 9, loss:  17586.2676, reconstruct loss:  15347.0391, KL loss:  2239.2292\n",
      "Epoch: 9, loss:  17193.5254, reconstruct loss:  14968.5215, KL loss:  2225.0039\n",
      "Epoch: 9, loss:  17276.0957, reconstruct loss:  15038.2539, KL loss:  2237.8423\n",
      "Epoch: 9, loss:  16846.1016, reconstruct loss:  14628.5039, KL loss:  2217.5981\n",
      "Epoch: 9, loss:  17149.0176, reconstruct loss:  14965.0332, KL loss:  2183.9844\n",
      "Epoch: 9, loss:  16573.7305, reconstruct loss:  14327.0771, KL loss:  2246.6536\n",
      "Epoch: 9, loss:  17012.6621, reconstruct loss:  14700.7051, KL loss:  2311.9575\n",
      "Epoch: 9, loss:  16609.1816, reconstruct loss:  14413.4473, KL loss:  2195.7336\n",
      "Epoch: 9, loss:  16350.7266, reconstruct loss:  14165.6445, KL loss:  2185.0820\n",
      "Epoch: 9, loss:  17294.4551, reconstruct loss:  15048.2783, KL loss:  2246.1768\n",
      "Epoch: 9, loss:  16319.7480, reconstruct loss:  14124.1885, KL loss:  2195.5596\n",
      "Epoch: 9, loss:  16820.0820, reconstruct loss:  14605.8252, KL loss:  2214.2576\n",
      "Epoch: 9, loss:  16702.5781, reconstruct loss:  14439.9512, KL loss:  2262.6270\n",
      "Epoch: 9, loss:  16642.1699, reconstruct loss:  14518.4023, KL loss:  2123.7668\n",
      "Epoch: 9, loss:  17075.0547, reconstruct loss:  14759.4766, KL loss:  2315.5784\n",
      "Epoch: 9, loss:  16406.9160, reconstruct loss:  14087.8730, KL loss:  2319.0432\n",
      "Epoch: 9, loss:  16364.4121, reconstruct loss:  14225.9258, KL loss:  2138.4863\n",
      "Epoch: 9, loss:  16967.6797, reconstruct loss:  14789.9648, KL loss:  2177.7158\n",
      "Epoch: 9, loss:  16357.9551, reconstruct loss:  14167.7949, KL loss:  2190.1602\n",
      "Epoch: 9, loss:  16841.6270, reconstruct loss:  14606.1367, KL loss:  2235.4902\n",
      "Epoch: 9, loss:  16455.4316, reconstruct loss:  14253.9170, KL loss:  2201.5151\n",
      "Epoch: 9, loss:  16476.1562, reconstruct loss:  14331.8789, KL loss:  2144.2778\n",
      "Epoch: 9, loss:  17042.2832, reconstruct loss:  14794.8262, KL loss:  2247.4563\n",
      "Epoch: 9, loss:  16525.6094, reconstruct loss:  14297.6953, KL loss:  2227.9138\n",
      "Epoch: 9, loss:  16446.2598, reconstruct loss:  14178.1230, KL loss:  2268.1372\n",
      "Epoch: 9, loss:  16780.6465, reconstruct loss:  14518.4902, KL loss:  2262.1560\n",
      "Epoch: 9, loss:  17003.2949, reconstruct loss:  14792.0234, KL loss:  2211.2717\n",
      "Epoch: 9, loss:  16818.6816, reconstruct loss:  14538.4004, KL loss:  2280.2820\n",
      "Epoch: 9, loss:  17180.5586, reconstruct loss:  14945.0371, KL loss:  2235.5210\n",
      "Epoch: 9, loss:  16535.3320, reconstruct loss:  14325.9062, KL loss:  2209.4248\n",
      "Epoch: 9, loss:  16423.0195, reconstruct loss:  14226.7158, KL loss:  2196.3042\n",
      "Epoch: 9, loss:  16092.5283, reconstruct loss:  13919.1758, KL loss:  2173.3528\n",
      "Epoch: 9, loss:  17313.7461, reconstruct loss:  15064.7803, KL loss:  2248.9663\n",
      "Epoch: 9, loss:  16083.3516, reconstruct loss:  13833.8711, KL loss:  2249.4805\n",
      "Epoch: 10, loss:  17606.7754, reconstruct loss:  15293.2383, KL loss:  2313.5376\n",
      "Epoch: 10, loss:  16866.8320, reconstruct loss:  14565.2051, KL loss:  2301.6274\n",
      "Epoch: 10, loss:  16041.0312, reconstruct loss:  13809.5137, KL loss:  2231.5178\n",
      "Epoch: 10, loss:  16581.9883, reconstruct loss:  14332.8916, KL loss:  2249.0969\n",
      "Epoch: 10, loss:  17388.2285, reconstruct loss:  15109.7383, KL loss:  2278.4907\n",
      "Epoch: 10, loss:  16499.0781, reconstruct loss:  14263.2568, KL loss:  2235.8218\n",
      "Epoch: 10, loss:  16939.5098, reconstruct loss:  14686.0371, KL loss:  2253.4734\n",
      "Epoch: 10, loss:  17556.3672, reconstruct loss:  15281.7617, KL loss:  2274.6060\n",
      "Epoch: 10, loss:  16518.5098, reconstruct loss:  14315.4277, KL loss:  2203.0818\n",
      "Epoch: 10, loss:  16583.7734, reconstruct loss:  14357.0723, KL loss:  2226.7014\n",
      "Epoch: 10, loss:  16793.7539, reconstruct loss:  14454.5371, KL loss:  2339.2173\n",
      "Epoch: 10, loss:  16483.6914, reconstruct loss:  14245.2451, KL loss:  2238.4458\n",
      "Epoch: 10, loss:  16759.5859, reconstruct loss:  14525.9336, KL loss:  2233.6528\n",
      "Epoch: 10, loss:  17275.1602, reconstruct loss:  15034.7871, KL loss:  2240.3723\n",
      "Epoch: 10, loss:  16098.1602, reconstruct loss:  13880.3418, KL loss:  2217.8186\n",
      "Epoch: 10, loss:  16278.5000, reconstruct loss:  14097.0469, KL loss:  2181.4529\n",
      "Epoch: 10, loss:  16447.5820, reconstruct loss:  14184.0264, KL loss:  2263.5547\n",
      "Epoch: 10, loss:  16352.3906, reconstruct loss:  14182.5840, KL loss:  2169.8071\n",
      "Epoch: 10, loss:  16214.3926, reconstruct loss:  13974.1465, KL loss:  2240.2456\n",
      "Epoch: 10, loss:  16484.8535, reconstruct loss:  14163.7441, KL loss:  2321.1099\n",
      "Epoch: 10, loss:  16648.3770, reconstruct loss:  14331.5713, KL loss:  2316.8052\n",
      "Epoch: 10, loss:  17024.0703, reconstruct loss:  14651.7383, KL loss:  2372.3323\n",
      "Epoch: 10, loss:  15937.8730, reconstruct loss:  13647.3926, KL loss:  2290.4802\n",
      "Epoch: 10, loss:  16919.2305, reconstruct loss:  14651.3145, KL loss:  2267.9170\n",
      "Epoch: 10, loss:  16271.7441, reconstruct loss:  14037.1328, KL loss:  2234.6108\n",
      "Epoch: 10, loss:  16011.1934, reconstruct loss:  13756.9092, KL loss:  2254.2847\n",
      "Epoch: 10, loss:  16728.3418, reconstruct loss:  14507.9102, KL loss:  2220.4312\n",
      "Epoch: 10, loss:  16929.3926, reconstruct loss:  14687.6406, KL loss:  2241.7524\n",
      "Epoch: 10, loss:  16746.2891, reconstruct loss:  14458.7598, KL loss:  2287.5303\n",
      "Epoch: 10, loss:  16477.6191, reconstruct loss:  14260.0605, KL loss:  2217.5586\n",
      "Epoch: 10, loss:  16005.3906, reconstruct loss:  13748.6348, KL loss:  2256.7559\n",
      "Epoch: 10, loss:  16446.9512, reconstruct loss:  14185.4570, KL loss:  2261.4941\n",
      "Epoch: 10, loss:  16898.1211, reconstruct loss:  14676.6250, KL loss:  2221.4961\n",
      "Epoch: 10, loss:  16581.8945, reconstruct loss:  14374.1953, KL loss:  2207.6982\n",
      "Epoch: 10, loss:  16304.8467, reconstruct loss:  14060.9004, KL loss:  2243.9463\n",
      "Epoch: 10, loss:  17028.6523, reconstruct loss:  14769.7178, KL loss:  2258.9336\n",
      "Epoch: 10, loss:  16461.0273, reconstruct loss:  14154.9443, KL loss:  2306.0825\n",
      "Epoch: 10, loss:  17190.8184, reconstruct loss:  14944.9863, KL loss:  2245.8313\n",
      "Epoch: 10, loss:  16155.7363, reconstruct loss:  13898.2520, KL loss:  2257.4849\n",
      "Epoch: 10, loss:  16237.8740, reconstruct loss:  13961.8672, KL loss:  2276.0068\n",
      "Epoch: 10, loss:  16938.8984, reconstruct loss:  14599.3857, KL loss:  2339.5127\n",
      "Epoch: 10, loss:  16653.5332, reconstruct loss:  14375.1992, KL loss:  2278.3335\n",
      "Epoch: 10, loss:  16921.7324, reconstruct loss:  14664.4902, KL loss:  2257.2417\n",
      "Epoch: 10, loss:  16752.6719, reconstruct loss:  14464.7422, KL loss:  2287.9290\n",
      "Epoch: 10, loss:  17714.5273, reconstruct loss:  15345.0840, KL loss:  2369.4434\n",
      "Epoch: 10, loss:  16520.9102, reconstruct loss:  14212.8828, KL loss:  2308.0278\n"
     ]
    }
   ],
   "source": [
    "# 予測⇒損失の計算⇒パラメータの更新⇒損失の表示\n",
    "losses = []\n",
    "# PyTorchではmodel.train()やmodel.eval()によって、モデルのモードを切り替えますが\n",
    "# これらのメソッドによってドロップアウトを行うか否かを自動で切り替えてくれるのは\n",
    "# ドロップアウトクラス（torch.nn.Dropout）の方です。torch.nn.functional.dropoutの方は\n",
    "# model.eval()などが働きません。\n",
    "# 関数の引数でtorch.nn.functional.dropout(training=False)などとしなければならないのです。​\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss = 0\n",
    "  # train_loaderが学習データ\n",
    "  for i, (x, labels) in enumerate(train_loader):\n",
    "    # 予測\n",
    "    # view(-1, 指定したいサイズ数)\n",
    "    x = x.to(device).view(-1, image_size).to(torch.float32)\n",
    "    x_recon, mu, log_var, z = model(x)\n",
    "    # 損失関数の計算\n",
    "    loss, recon_loss, kl_loss = loss_function(x, x_recon, mu, log_var)\n",
    "     \n",
    "    # パラメータの更新\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "     \n",
    "    # 損失の表示\n",
    "    if (i+1) % 10 == 0:\n",
    "      print(f'Epoch: {epoch+1}, loss: {loss: 0.4f}, reconstruct loss: {recon_loss: 0.4f}, KL loss: {kl_loss: 0.4f}')\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(label, predict, mu, log_var):\n",
    "  reconstruction_loss = F.binary_cross_entropy(predict, label, reduction='sum')\n",
    "  kl_loss = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "  vae_loss = reconstruction_loss + kl_loss\n",
    "  return vae_loss, reconstruction_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 * 28\n",
    "h_dim = 32\n",
    "z_dim = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    " \n",
    "model = VAE(image_size, h_dim, z_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss:  67820.0938, reconstruct loss:  67718.9375, KL loss:  101.1570\n",
      "Epoch: 1, loss:  63414.6250, reconstruct loss:  62852.0547, KL loss:  562.5718\n",
      "Epoch: 1, loss:  54608.6719, reconstruct loss:  52324.1016, KL loss:  2284.5684\n",
      "Epoch: 1, loss:  45038.5195, reconstruct loss:  40639.2422, KL loss:  4399.2764\n",
      "Epoch: 1, loss:  37659.3516, reconstruct loss:  34108.9219, KL loss:  3550.4280\n",
      "Epoch: 1, loss:  33651.3789, reconstruct loss:  30531.3398, KL loss:  3120.0405\n",
      "Epoch: 1, loss:  32124.7930, reconstruct loss:  29278.3750, KL loss:  2846.4189\n",
      "Epoch: 1, loss:  30383.2539, reconstruct loss:  27732.1875, KL loss:  2651.0659\n",
      "Epoch: 1, loss:  30832.9980, reconstruct loss:  28858.4219, KL loss:  1974.5764\n",
      "Epoch: 1, loss:  29156.2969, reconstruct loss:  27046.1992, KL loss:  2110.0974\n",
      "Epoch: 1, loss:  29194.3809, reconstruct loss:  27408.5703, KL loss:  1785.8110\n",
      "Epoch: 1, loss:  28406.4473, reconstruct loss:  26820.3477, KL loss:  1586.0988\n",
      "Epoch: 1, loss:  29480.5762, reconstruct loss:  27859.0938, KL loss:  1621.4822\n",
      "Epoch: 1, loss:  27619.8945, reconstruct loss:  25928.7070, KL loss:  1691.1873\n",
      "Epoch: 1, loss:  28341.5898, reconstruct loss:  26793.0195, KL loss:  1548.5693\n",
      "Epoch: 1, loss:  28770.5977, reconstruct loss:  27436.7383, KL loss:  1333.8595\n",
      "Epoch: 1, loss:  28817.3418, reconstruct loss:  27417.2031, KL loss:  1400.1394\n",
      "Epoch: 1, loss:  27539.9922, reconstruct loss:  26193.6680, KL loss:  1346.3242\n",
      "Epoch: 1, loss:  27594.4492, reconstruct loss:  26148.3672, KL loss:  1446.0811\n",
      "Epoch: 1, loss:  27367.5957, reconstruct loss:  25954.9062, KL loss:  1412.6887\n",
      "Epoch: 1, loss:  28117.7734, reconstruct loss:  26889.3633, KL loss:  1228.4093\n",
      "Epoch: 1, loss:  26745.4141, reconstruct loss:  25335.5977, KL loss:  1409.8158\n",
      "Epoch: 1, loss:  28102.6367, reconstruct loss:  26826.6055, KL loss:  1276.0314\n",
      "Epoch: 1, loss:  27795.2129, reconstruct loss:  26478.9531, KL loss:  1316.2598\n",
      "Epoch: 1, loss:  26135.6074, reconstruct loss:  24710.5938, KL loss:  1425.0143\n",
      "Epoch: 1, loss:  27035.6914, reconstruct loss:  25724.2559, KL loss:  1311.4357\n",
      "Epoch: 1, loss:  26371.8867, reconstruct loss:  25049.3008, KL loss:  1322.5864\n",
      "Epoch: 1, loss:  26355.0312, reconstruct loss:  25033.5000, KL loss:  1321.5308\n",
      "Epoch: 1, loss:  26525.7441, reconstruct loss:  25068.0938, KL loss:  1457.6510\n",
      "Epoch: 1, loss:  26348.7676, reconstruct loss:  25082.4883, KL loss:  1266.2788\n",
      "Epoch: 1, loss:  26142.9473, reconstruct loss:  24777.8535, KL loss:  1365.0941\n",
      "Epoch: 1, loss:  26161.0137, reconstruct loss:  24817.2988, KL loss:  1343.7151\n",
      "Epoch: 1, loss:  25725.1348, reconstruct loss:  24410.3281, KL loss:  1314.8071\n",
      "Epoch: 1, loss:  26039.8242, reconstruct loss:  24694.0566, KL loss:  1345.7673\n",
      "Epoch: 1, loss:  25461.0176, reconstruct loss:  24167.3125, KL loss:  1293.7043\n",
      "Epoch: 1, loss:  25562.2129, reconstruct loss:  24192.4219, KL loss:  1369.7913\n",
      "Epoch: 1, loss:  26422.9824, reconstruct loss:  25058.6367, KL loss:  1364.3461\n",
      "Epoch: 1, loss:  25612.0098, reconstruct loss:  24148.9141, KL loss:  1463.0958\n",
      "Epoch: 1, loss:  25405.3477, reconstruct loss:  24026.3008, KL loss:  1379.0460\n",
      "Epoch: 1, loss:  24918.5430, reconstruct loss:  23485.6484, KL loss:  1432.8953\n",
      "Epoch: 1, loss:  24340.4531, reconstruct loss:  22776.3008, KL loss:  1564.1516\n",
      "Epoch: 1, loss:  24429.6699, reconstruct loss:  22952.1348, KL loss:  1477.5354\n",
      "Epoch: 1, loss:  25391.2793, reconstruct loss:  23953.1152, KL loss:  1438.1633\n",
      "Epoch: 1, loss:  24640.9180, reconstruct loss:  23155.6914, KL loss:  1485.2266\n",
      "Epoch: 1, loss:  22790.2480, reconstruct loss:  21095.7734, KL loss:  1694.4749\n",
      "Epoch: 1, loss:  24481.6152, reconstruct loss:  23034.6641, KL loss:  1446.9512\n",
      "Epoch: 2, loss:  24056.4863, reconstruct loss:  22541.1191, KL loss:  1515.3678\n",
      "Epoch: 2, loss:  23855.1074, reconstruct loss:  22323.6758, KL loss:  1531.4309\n",
      "Epoch: 2, loss:  25523.5371, reconstruct loss:  24022.4531, KL loss:  1501.0833\n",
      "Epoch: 2, loss:  23188.2871, reconstruct loss:  21600.3711, KL loss:  1587.9167\n",
      "Epoch: 2, loss:  23401.1152, reconstruct loss:  21891.3594, KL loss:  1509.7563\n",
      "Epoch: 2, loss:  24021.3125, reconstruct loss:  22521.7969, KL loss:  1499.5161\n",
      "Epoch: 2, loss:  22946.7422, reconstruct loss:  21468.0859, KL loss:  1478.6559\n",
      "Epoch: 2, loss:  23634.7500, reconstruct loss:  22120.0918, KL loss:  1514.6581\n",
      "Epoch: 2, loss:  22438.1191, reconstruct loss:  20937.0000, KL loss:  1501.1184\n",
      "Epoch: 2, loss:  23506.2305, reconstruct loss:  21962.8125, KL loss:  1543.4171\n",
      "Epoch: 2, loss:  22279.6055, reconstruct loss:  20795.2207, KL loss:  1484.3855\n",
      "Epoch: 2, loss:  23470.9707, reconstruct loss:  21876.0996, KL loss:  1594.8708\n",
      "Epoch: 2, loss:  23584.7520, reconstruct loss:  22054.2441, KL loss:  1530.5077\n",
      "Epoch: 2, loss:  23684.0820, reconstruct loss:  22101.9824, KL loss:  1582.0996\n",
      "Epoch: 2, loss:  22604.8730, reconstruct loss:  20936.6016, KL loss:  1668.2720\n",
      "Epoch: 2, loss:  22195.7656, reconstruct loss:  20644.5547, KL loss:  1551.2102\n",
      "Epoch: 2, loss:  22537.8926, reconstruct loss:  20927.2207, KL loss:  1610.6715\n",
      "Epoch: 2, loss:  22790.8789, reconstruct loss:  21219.5430, KL loss:  1571.3357\n",
      "Epoch: 2, loss:  22168.8496, reconstruct loss:  20551.3828, KL loss:  1617.4668\n",
      "Epoch: 2, loss:  22595.5566, reconstruct loss:  21002.7461, KL loss:  1592.8104\n",
      "Epoch: 2, loss:  21938.1719, reconstruct loss:  20208.8203, KL loss:  1729.3518\n",
      "Epoch: 2, loss:  22275.1602, reconstruct loss:  20641.1680, KL loss:  1633.9932\n",
      "Epoch: 2, loss:  22133.8984, reconstruct loss:  20461.6680, KL loss:  1672.2313\n",
      "Epoch: 2, loss:  21664.5156, reconstruct loss:  20060.8008, KL loss:  1603.7146\n",
      "Epoch: 2, loss:  22898.6133, reconstruct loss:  21252.3359, KL loss:  1646.2769\n",
      "Epoch: 2, loss:  23897.0996, reconstruct loss:  22164.9629, KL loss:  1732.1372\n",
      "Epoch: 2, loss:  22025.1270, reconstruct loss:  20372.2031, KL loss:  1652.9232\n",
      "Epoch: 2, loss:  22840.6660, reconstruct loss:  21163.9727, KL loss:  1676.6929\n",
      "Epoch: 2, loss:  22353.5293, reconstruct loss:  20651.2812, KL loss:  1702.2483\n",
      "Epoch: 2, loss:  22117.5312, reconstruct loss:  20558.3965, KL loss:  1559.1345\n",
      "Epoch: 2, loss:  21529.1113, reconstruct loss:  19899.2461, KL loss:  1629.8645\n",
      "Epoch: 2, loss:  22069.2598, reconstruct loss:  20332.3652, KL loss:  1736.8948\n",
      "Epoch: 2, loss:  22123.0898, reconstruct loss:  20351.3672, KL loss:  1771.7236\n",
      "Epoch: 2, loss:  21758.5254, reconstruct loss:  20010.6914, KL loss:  1747.8347\n",
      "Epoch: 2, loss:  21645.9590, reconstruct loss:  19916.3203, KL loss:  1729.6379\n",
      "Epoch: 2, loss:  21826.3770, reconstruct loss:  20159.3047, KL loss:  1667.0731\n",
      "Epoch: 2, loss:  21563.1602, reconstruct loss:  19834.9473, KL loss:  1728.2134\n",
      "Epoch: 2, loss:  22005.6602, reconstruct loss:  20353.1484, KL loss:  1652.5107\n",
      "Epoch: 2, loss:  21469.9570, reconstruct loss:  19752.3242, KL loss:  1717.6328\n",
      "Epoch: 2, loss:  21839.4375, reconstruct loss:  20072.8242, KL loss:  1766.6143\n",
      "Epoch: 2, loss:  21414.7988, reconstruct loss:  19619.8711, KL loss:  1794.9274\n",
      "Epoch: 2, loss:  20738.2695, reconstruct loss:  18975.2734, KL loss:  1762.9955\n",
      "Epoch: 2, loss:  20835.8535, reconstruct loss:  19078.5879, KL loss:  1757.2656\n",
      "Epoch: 2, loss:  20767.5332, reconstruct loss:  18934.4961, KL loss:  1833.0376\n",
      "Epoch: 2, loss:  21369.5840, reconstruct loss:  19434.4844, KL loss:  1935.0999\n",
      "Epoch: 2, loss:  21642.3223, reconstruct loss:  19832.6758, KL loss:  1809.6466\n",
      "Epoch: 3, loss:  20266.4824, reconstruct loss:  18488.5547, KL loss:  1777.9269\n",
      "Epoch: 3, loss:  20577.7910, reconstruct loss:  18691.0879, KL loss:  1886.7032\n",
      "Epoch: 3, loss:  21068.9023, reconstruct loss:  19227.4922, KL loss:  1841.4102\n",
      "Epoch: 3, loss:  20517.3672, reconstruct loss:  18569.6719, KL loss:  1947.6953\n",
      "Epoch: 3, loss:  21000.5332, reconstruct loss:  19195.0508, KL loss:  1805.4817\n",
      "Epoch: 3, loss:  21388.7227, reconstruct loss:  19577.0605, KL loss:  1811.6611\n",
      "Epoch: 3, loss:  20439.6270, reconstruct loss:  18540.5391, KL loss:  1899.0886\n",
      "Epoch: 3, loss:  20254.1602, reconstruct loss:  18387.8770, KL loss:  1866.2838\n",
      "Epoch: 3, loss:  20262.2363, reconstruct loss:  18260.2344, KL loss:  2002.0027\n",
      "Epoch: 3, loss:  20914.8438, reconstruct loss:  19027.3809, KL loss:  1887.4634\n",
      "Epoch: 3, loss:  19870.2891, reconstruct loss:  17996.5645, KL loss:  1873.7256\n",
      "Epoch: 3, loss:  21197.2090, reconstruct loss:  19313.8516, KL loss:  1883.3583\n",
      "Epoch: 3, loss:  21275.8809, reconstruct loss:  19410.2559, KL loss:  1865.6251\n",
      "Epoch: 3, loss:  20006.5645, reconstruct loss:  18204.8516, KL loss:  1801.7122\n",
      "Epoch: 3, loss:  20784.1602, reconstruct loss:  18995.2695, KL loss:  1788.8900\n",
      "Epoch: 3, loss:  20606.4160, reconstruct loss:  18809.7793, KL loss:  1796.6372\n",
      "Epoch: 3, loss:  20237.9160, reconstruct loss:  18372.3086, KL loss:  1865.6075\n",
      "Epoch: 3, loss:  19809.2129, reconstruct loss:  17981.9531, KL loss:  1827.2605\n",
      "Epoch: 3, loss:  20913.7754, reconstruct loss:  19058.6055, KL loss:  1855.1702\n",
      "Epoch: 3, loss:  20427.7051, reconstruct loss:  18564.8750, KL loss:  1862.8304\n",
      "Epoch: 3, loss:  19792.3984, reconstruct loss:  17930.5781, KL loss:  1861.8208\n",
      "Epoch: 3, loss:  20961.0703, reconstruct loss:  19122.9102, KL loss:  1838.1604\n",
      "Epoch: 3, loss:  20330.1289, reconstruct loss:  18544.7188, KL loss:  1785.4108\n",
      "Epoch: 3, loss:  20939.5547, reconstruct loss:  19100.6816, KL loss:  1838.8735\n",
      "Epoch: 3, loss:  21051.4238, reconstruct loss:  19064.1855, KL loss:  1987.2374\n",
      "Epoch: 3, loss:  20089.2090, reconstruct loss:  18244.8086, KL loss:  1844.4010\n",
      "Epoch: 3, loss:  20535.4141, reconstruct loss:  18667.6250, KL loss:  1867.7885\n",
      "Epoch: 3, loss:  19816.3906, reconstruct loss:  18072.6348, KL loss:  1743.7566\n",
      "Epoch: 3, loss:  19294.9238, reconstruct loss:  17506.1562, KL loss:  1788.7673\n",
      "Epoch: 3, loss:  20314.9941, reconstruct loss:  18381.8516, KL loss:  1933.1423\n",
      "Epoch: 3, loss:  20371.2793, reconstruct loss:  18513.1152, KL loss:  1858.1636\n",
      "Epoch: 3, loss:  19891.7441, reconstruct loss:  17980.0195, KL loss:  1911.7242\n",
      "Epoch: 3, loss:  20178.5273, reconstruct loss:  18300.9922, KL loss:  1877.5356\n",
      "Epoch: 3, loss:  19671.7598, reconstruct loss:  17821.4883, KL loss:  1850.2720\n",
      "Epoch: 3, loss:  19834.2305, reconstruct loss:  17997.3945, KL loss:  1836.8362\n",
      "Epoch: 3, loss:  19862.4180, reconstruct loss:  18029.6523, KL loss:  1832.7664\n",
      "Epoch: 3, loss:  20381.7148, reconstruct loss:  18423.5332, KL loss:  1958.1808\n",
      "Epoch: 3, loss:  20332.2539, reconstruct loss:  18452.6016, KL loss:  1879.6531\n",
      "Epoch: 3, loss:  18523.1875, reconstruct loss:  16614.3477, KL loss:  1908.8408\n",
      "Epoch: 3, loss:  20290.7402, reconstruct loss:  18387.2676, KL loss:  1903.4733\n",
      "Epoch: 3, loss:  19635.4863, reconstruct loss:  17681.3086, KL loss:  1954.1769\n",
      "Epoch: 3, loss:  20046.7676, reconstruct loss:  18218.1211, KL loss:  1828.6466\n",
      "Epoch: 3, loss:  19476.6074, reconstruct loss:  17604.9883, KL loss:  1871.6193\n",
      "Epoch: 3, loss:  20100.7402, reconstruct loss:  18237.8945, KL loss:  1862.8448\n",
      "Epoch: 3, loss:  20511.9805, reconstruct loss:  18579.3125, KL loss:  1932.6672\n",
      "Epoch: 3, loss:  20019.3594, reconstruct loss:  18171.3789, KL loss:  1847.9801\n",
      "Epoch: 4, loss:  19761.1875, reconstruct loss:  17884.9883, KL loss:  1876.1990\n",
      "Epoch: 4, loss:  19722.0156, reconstruct loss:  17803.2578, KL loss:  1918.7578\n",
      "Epoch: 4, loss:  19410.8242, reconstruct loss:  17525.4180, KL loss:  1885.4053\n",
      "Epoch: 4, loss:  20197.5234, reconstruct loss:  18186.3281, KL loss:  2011.1963\n",
      "Epoch: 4, loss:  19443.9180, reconstruct loss:  17522.2383, KL loss:  1921.6798\n",
      "Epoch: 4, loss:  19984.4336, reconstruct loss:  18032.3574, KL loss:  1952.0757\n",
      "Epoch: 4, loss:  19677.0527, reconstruct loss:  17658.7285, KL loss:  2018.3251\n",
      "Epoch: 4, loss:  20018.6992, reconstruct loss:  18079.3379, KL loss:  1939.3616\n",
      "Epoch: 4, loss:  19151.8691, reconstruct loss:  17130.6777, KL loss:  2021.1921\n",
      "Epoch: 4, loss:  19767.7617, reconstruct loss:  17824.4355, KL loss:  1943.3263\n",
      "Epoch: 4, loss:  19572.3906, reconstruct loss:  17602.9141, KL loss:  1969.4774\n",
      "Epoch: 4, loss:  19345.9531, reconstruct loss:  17414.7148, KL loss:  1931.2377\n",
      "Epoch: 4, loss:  19531.9961, reconstruct loss:  17566.1055, KL loss:  1965.8906\n",
      "Epoch: 4, loss:  19911.5801, reconstruct loss:  17957.7520, KL loss:  1953.8279\n",
      "Epoch: 4, loss:  18809.9629, reconstruct loss:  16888.7695, KL loss:  1921.1938\n",
      "Epoch: 4, loss:  19225.2051, reconstruct loss:  17149.5742, KL loss:  2075.6306\n",
      "Epoch: 4, loss:  19495.3574, reconstruct loss:  17503.5703, KL loss:  1991.7872\n",
      "Epoch: 4, loss:  18598.1875, reconstruct loss:  16677.2070, KL loss:  1920.9811\n",
      "Epoch: 4, loss:  19466.6367, reconstruct loss:  17530.2070, KL loss:  1936.4298\n",
      "Epoch: 4, loss:  19748.3242, reconstruct loss:  17712.4941, KL loss:  2035.8302\n",
      "Epoch: 4, loss:  18729.4648, reconstruct loss:  16733.2812, KL loss:  1996.1846\n",
      "Epoch: 4, loss:  19527.9512, reconstruct loss:  17554.6348, KL loss:  1973.3162\n",
      "Epoch: 4, loss:  19213.6211, reconstruct loss:  17241.1816, KL loss:  1972.4398\n",
      "Epoch: 4, loss:  19116.1660, reconstruct loss:  17007.3281, KL loss:  2108.8376\n",
      "Epoch: 4, loss:  19192.5371, reconstruct loss:  17258.7109, KL loss:  1933.8269\n",
      "Epoch: 4, loss:  18754.5996, reconstruct loss:  16769.0312, KL loss:  1985.5680\n",
      "Epoch: 4, loss:  18933.5801, reconstruct loss:  16908.1211, KL loss:  2025.4587\n",
      "Epoch: 4, loss:  18327.5840, reconstruct loss:  16333.0908, KL loss:  1994.4937\n",
      "Epoch: 4, loss:  18980.0527, reconstruct loss:  16996.8164, KL loss:  1983.2363\n",
      "Epoch: 4, loss:  19092.5586, reconstruct loss:  17030.0156, KL loss:  2062.5425\n",
      "Epoch: 4, loss:  17976.2891, reconstruct loss:  15960.6504, KL loss:  2015.6394\n",
      "Epoch: 4, loss:  18938.8887, reconstruct loss:  16940.3320, KL loss:  1998.5558\n",
      "Epoch: 4, loss:  18563.1465, reconstruct loss:  16492.6465, KL loss:  2070.4998\n",
      "Epoch: 4, loss:  18564.3848, reconstruct loss:  16597.3359, KL loss:  1967.0497\n",
      "Epoch: 4, loss:  18316.8672, reconstruct loss:  16335.4229, KL loss:  1981.4445\n",
      "Epoch: 4, loss:  18604.5195, reconstruct loss:  16564.0977, KL loss:  2040.4227\n",
      "Epoch: 4, loss:  19103.6484, reconstruct loss:  17069.4199, KL loss:  2034.2279\n",
      "Epoch: 4, loss:  18901.3789, reconstruct loss:  16933.8047, KL loss:  1967.5750\n",
      "Epoch: 4, loss:  18713.5410, reconstruct loss:  16702.0000, KL loss:  2011.5403\n",
      "Epoch: 4, loss:  18852.0918, reconstruct loss:  16739.9961, KL loss:  2112.0957\n",
      "Epoch: 4, loss:  18411.1055, reconstruct loss:  16421.9531, KL loss:  1989.1523\n",
      "Epoch: 4, loss:  18763.3086, reconstruct loss:  16719.1094, KL loss:  2044.1990\n",
      "Epoch: 4, loss:  18526.6289, reconstruct loss:  16550.9609, KL loss:  1975.6685\n",
      "Epoch: 4, loss:  19221.7012, reconstruct loss:  17209.8008, KL loss:  2011.9011\n",
      "Epoch: 4, loss:  18151.0000, reconstruct loss:  16069.6963, KL loss:  2081.3042\n",
      "Epoch: 4, loss:  19198.9102, reconstruct loss:  17152.6562, KL loss:  2046.2539\n",
      "Epoch: 5, loss:  19117.0098, reconstruct loss:  16959.1328, KL loss:  2157.8765\n",
      "Epoch: 5, loss:  18662.9688, reconstruct loss:  16634.6523, KL loss:  2028.3157\n",
      "Epoch: 5, loss:  18218.2578, reconstruct loss:  16189.0723, KL loss:  2029.1859\n",
      "Epoch: 5, loss:  18703.2324, reconstruct loss:  16627.7480, KL loss:  2075.4849\n",
      "Epoch: 5, loss:  18155.5137, reconstruct loss:  16040.3672, KL loss:  2115.1460\n",
      "Epoch: 5, loss:  18973.9277, reconstruct loss:  16932.5156, KL loss:  2041.4121\n",
      "Epoch: 5, loss:  19467.6367, reconstruct loss:  17410.9121, KL loss:  2056.7246\n",
      "Epoch: 5, loss:  19101.3320, reconstruct loss:  16997.4375, KL loss:  2103.8936\n",
      "Epoch: 5, loss:  18492.7773, reconstruct loss:  16402.4434, KL loss:  2090.3340\n",
      "Epoch: 5, loss:  18679.1113, reconstruct loss:  16658.1426, KL loss:  2020.9690\n",
      "Epoch: 5, loss:  18311.2148, reconstruct loss:  16319.8262, KL loss:  1991.3889\n",
      "Epoch: 5, loss:  18535.8242, reconstruct loss:  16541.3281, KL loss:  1994.4951\n",
      "Epoch: 5, loss:  18951.4180, reconstruct loss:  16904.2383, KL loss:  2047.1796\n",
      "Epoch: 5, loss:  19426.0840, reconstruct loss:  17376.0957, KL loss:  2049.9878\n",
      "Epoch: 5, loss:  18218.2109, reconstruct loss:  16179.0117, KL loss:  2039.2002\n",
      "Epoch: 5, loss:  18729.0371, reconstruct loss:  16731.2285, KL loss:  1997.8086\n",
      "Epoch: 5, loss:  18883.6230, reconstruct loss:  16933.3750, KL loss:  1950.2473\n",
      "Epoch: 5, loss:  17675.8730, reconstruct loss:  15613.8750, KL loss:  2061.9978\n",
      "Epoch: 5, loss:  18427.7598, reconstruct loss:  16453.2949, KL loss:  1974.4651\n",
      "Epoch: 5, loss:  19046.2539, reconstruct loss:  16969.7461, KL loss:  2076.5068\n",
      "Epoch: 5, loss:  18338.7070, reconstruct loss:  16371.7822, KL loss:  1966.9252\n",
      "Epoch: 5, loss:  18387.0684, reconstruct loss:  16428.1914, KL loss:  1958.8773\n",
      "Epoch: 5, loss:  19354.2227, reconstruct loss:  17356.6523, KL loss:  1997.5710\n",
      "Epoch: 5, loss:  18471.9336, reconstruct loss:  16442.1602, KL loss:  2029.7734\n",
      "Epoch: 5, loss:  18325.2402, reconstruct loss:  16300.3281, KL loss:  2024.9115\n",
      "Epoch: 5, loss:  18862.7500, reconstruct loss:  16830.9102, KL loss:  2031.8401\n",
      "Epoch: 5, loss:  18524.8906, reconstruct loss:  16426.0938, KL loss:  2098.7964\n",
      "Epoch: 5, loss:  18711.5469, reconstruct loss:  16664.3496, KL loss:  2047.1980\n",
      "Epoch: 5, loss:  17942.4961, reconstruct loss:  15838.8711, KL loss:  2103.6248\n",
      "Epoch: 5, loss:  18167.8184, reconstruct loss:  16180.2832, KL loss:  1987.5347\n",
      "Epoch: 5, loss:  18655.0195, reconstruct loss:  16534.7832, KL loss:  2120.2358\n",
      "Epoch: 5, loss:  17975.0156, reconstruct loss:  15879.6963, KL loss:  2095.3203\n",
      "Epoch: 5, loss:  18810.8711, reconstruct loss:  16770.7578, KL loss:  2040.1143\n",
      "Epoch: 5, loss:  18331.7715, reconstruct loss:  16358.7734, KL loss:  1972.9984\n",
      "Epoch: 5, loss:  17923.1504, reconstruct loss:  15840.5703, KL loss:  2082.5806\n",
      "Epoch: 5, loss:  17696.3594, reconstruct loss:  15702.5840, KL loss:  1993.7751\n",
      "Epoch: 5, loss:  18650.2520, reconstruct loss:  16623.9629, KL loss:  2026.2891\n",
      "Epoch: 5, loss:  18421.1621, reconstruct loss:  16435.1797, KL loss:  1985.9817\n",
      "Epoch: 5, loss:  18359.7246, reconstruct loss:  16304.5645, KL loss:  2055.1599\n",
      "Epoch: 5, loss:  18281.2637, reconstruct loss:  16197.0352, KL loss:  2084.2283\n",
      "Epoch: 5, loss:  18655.2871, reconstruct loss:  16607.1738, KL loss:  2048.1128\n",
      "Epoch: 5, loss:  18349.5723, reconstruct loss:  16338.7324, KL loss:  2010.8394\n",
      "Epoch: 5, loss:  18310.4023, reconstruct loss:  16321.5234, KL loss:  1988.8787\n",
      "Epoch: 5, loss:  18276.3027, reconstruct loss:  16184.2637, KL loss:  2092.0386\n",
      "Epoch: 5, loss:  17791.9688, reconstruct loss:  15758.7715, KL loss:  2033.1980\n",
      "Epoch: 5, loss:  17743.3438, reconstruct loss:  15754.6846, KL loss:  1988.6598\n",
      "Epoch: 6, loss:  18692.4863, reconstruct loss:  16647.6836, KL loss:  2044.8024\n",
      "Epoch: 6, loss:  17971.1387, reconstruct loss:  15876.1553, KL loss:  2094.9839\n",
      "Epoch: 6, loss:  17837.9082, reconstruct loss:  15843.2803, KL loss:  1994.6287\n",
      "Epoch: 6, loss:  17989.6191, reconstruct loss:  15985.0176, KL loss:  2004.6024\n",
      "Epoch: 6, loss:  18901.1211, reconstruct loss:  16858.0664, KL loss:  2043.0542\n",
      "Epoch: 6, loss:  18028.5176, reconstruct loss:  16015.0918, KL loss:  2013.4253\n",
      "Epoch: 6, loss:  18596.3945, reconstruct loss:  16547.5078, KL loss:  2048.8860\n",
      "Epoch: 6, loss:  17742.4805, reconstruct loss:  15726.9609, KL loss:  2015.5205\n",
      "Epoch: 6, loss:  17910.4688, reconstruct loss:  15934.1123, KL loss:  1976.3569\n",
      "Epoch: 6, loss:  18276.8984, reconstruct loss:  16309.7246, KL loss:  1967.1730\n",
      "Epoch: 6, loss:  17955.0898, reconstruct loss:  15903.1562, KL loss:  2051.9331\n",
      "Epoch: 6, loss:  17949.0898, reconstruct loss:  15831.8252, KL loss:  2117.2644\n",
      "Epoch: 6, loss:  17610.5586, reconstruct loss:  15576.7051, KL loss:  2033.8538\n",
      "Epoch: 6, loss:  18465.9414, reconstruct loss:  16412.4434, KL loss:  2053.4988\n",
      "Epoch: 6, loss:  17951.3652, reconstruct loss:  15923.7305, KL loss:  2027.6339\n",
      "Epoch: 6, loss:  18343.4824, reconstruct loss:  16283.1143, KL loss:  2060.3682\n",
      "Epoch: 6, loss:  18347.2051, reconstruct loss:  16373.7080, KL loss:  1973.4965\n",
      "Epoch: 6, loss:  17093.0195, reconstruct loss:  15124.9512, KL loss:  1968.0684\n",
      "Epoch: 6, loss:  17675.1543, reconstruct loss:  15673.1328, KL loss:  2002.0209\n",
      "Epoch: 6, loss:  17720.4062, reconstruct loss:  15719.4883, KL loss:  2000.9180\n",
      "Epoch: 6, loss:  19420.3145, reconstruct loss:  17290.3105, KL loss:  2130.0044\n",
      "Epoch: 6, loss:  18287.8945, reconstruct loss:  16292.8594, KL loss:  1995.0347\n",
      "Epoch: 6, loss:  18004.9355, reconstruct loss:  16016.0996, KL loss:  1988.8365\n",
      "Epoch: 6, loss:  18012.2383, reconstruct loss:  15941.1514, KL loss:  2071.0859\n",
      "Epoch: 6, loss:  18132.8203, reconstruct loss:  16188.3535, KL loss:  1944.4670\n",
      "Epoch: 6, loss:  17901.0059, reconstruct loss:  15908.3535, KL loss:  1992.6528\n",
      "Epoch: 6, loss:  17774.9863, reconstruct loss:  15814.4141, KL loss:  1960.5726\n",
      "Epoch: 6, loss:  18373.1016, reconstruct loss:  16361.8730, KL loss:  2011.2289\n",
      "Epoch: 6, loss:  18146.9531, reconstruct loss:  16131.7422, KL loss:  2015.2100\n",
      "Epoch: 6, loss:  17365.9395, reconstruct loss:  15362.6621, KL loss:  2003.2778\n",
      "Epoch: 6, loss:  18013.3438, reconstruct loss:  15993.9824, KL loss:  2019.3619\n",
      "Epoch: 6, loss:  17427.3828, reconstruct loss:  15492.5117, KL loss:  1934.8707\n",
      "Epoch: 6, loss:  18189.9238, reconstruct loss:  16267.8398, KL loss:  1922.0833\n",
      "Epoch: 6, loss:  17697.9453, reconstruct loss:  15766.8750, KL loss:  1931.0703\n",
      "Epoch: 6, loss:  17875.7246, reconstruct loss:  15880.7744, KL loss:  1994.9493\n",
      "Epoch: 6, loss:  17184.0156, reconstruct loss:  15224.3633, KL loss:  1959.6519\n",
      "Epoch: 6, loss:  18670.8125, reconstruct loss:  16582.9102, KL loss:  2087.9033\n",
      "Epoch: 6, loss:  18251.8633, reconstruct loss:  16266.9668, KL loss:  1984.8960\n",
      "Epoch: 6, loss:  17229.6094, reconstruct loss:  15186.1328, KL loss:  2043.4761\n",
      "Epoch: 6, loss:  17424.1602, reconstruct loss:  15480.4570, KL loss:  1943.7029\n",
      "Epoch: 6, loss:  17660.7441, reconstruct loss:  15628.6973, KL loss:  2032.0469\n",
      "Epoch: 6, loss:  17398.8125, reconstruct loss:  15349.7344, KL loss:  2049.0771\n",
      "Epoch: 6, loss:  18059.8945, reconstruct loss:  15928.9004, KL loss:  2130.9944\n",
      "Epoch: 6, loss:  17457.1953, reconstruct loss:  15533.8633, KL loss:  1923.3326\n",
      "Epoch: 6, loss:  17264.4922, reconstruct loss:  15296.9336, KL loss:  1967.5576\n",
      "Epoch: 6, loss:  17961.3926, reconstruct loss:  15897.7734, KL loss:  2063.6191\n",
      "Epoch: 7, loss:  18312.5840, reconstruct loss:  16314.8711, KL loss:  1997.7135\n",
      "Epoch: 7, loss:  18227.9238, reconstruct loss:  16206.9229, KL loss:  2021.0015\n",
      "Epoch: 7, loss:  17432.6523, reconstruct loss:  15430.0791, KL loss:  2002.5723\n",
      "Epoch: 7, loss:  17443.1270, reconstruct loss:  15434.6982, KL loss:  2008.4292\n",
      "Epoch: 7, loss:  17102.7070, reconstruct loss:  15064.8301, KL loss:  2037.8765\n",
      "Epoch: 7, loss:  17447.2891, reconstruct loss:  15420.4590, KL loss:  2026.8307\n",
      "Epoch: 7, loss:  16906.7305, reconstruct loss:  14927.5449, KL loss:  1979.1852\n",
      "Epoch: 7, loss:  17542.2852, reconstruct loss:  15564.3828, KL loss:  1977.9021\n",
      "Epoch: 7, loss:  18226.2090, reconstruct loss:  16123.6182, KL loss:  2102.5916\n",
      "Epoch: 7, loss:  16861.7480, reconstruct loss:  14854.4473, KL loss:  2007.3005\n",
      "Epoch: 7, loss:  16992.4141, reconstruct loss:  15013.0029, KL loss:  1979.4120\n",
      "Epoch: 7, loss:  17658.3711, reconstruct loss:  15693.0000, KL loss:  1965.3713\n",
      "Epoch: 7, loss:  16622.6758, reconstruct loss:  14657.5938, KL loss:  1965.0826\n",
      "Epoch: 7, loss:  17087.8027, reconstruct loss:  15067.3936, KL loss:  2020.4087\n",
      "Epoch: 7, loss:  17540.9102, reconstruct loss:  15453.1719, KL loss:  2087.7393\n",
      "Epoch: 7, loss:  17490.2754, reconstruct loss:  15469.9023, KL loss:  2020.3727\n",
      "Epoch: 7, loss:  17972.2285, reconstruct loss:  16044.6641, KL loss:  1927.5642\n",
      "Epoch: 7, loss:  17082.9805, reconstruct loss:  15041.5322, KL loss:  2041.4478\n",
      "Epoch: 7, loss:  17777.1758, reconstruct loss:  15743.5703, KL loss:  2033.6058\n",
      "Epoch: 7, loss:  17555.6797, reconstruct loss:  15517.2627, KL loss:  2038.4163\n",
      "Epoch: 7, loss:  17211.0273, reconstruct loss:  15208.1367, KL loss:  2002.8901\n",
      "Epoch: 7, loss:  17994.4883, reconstruct loss:  15996.5820, KL loss:  1997.9066\n",
      "Epoch: 7, loss:  17458.7617, reconstruct loss:  15480.2812, KL loss:  1978.4800\n",
      "Epoch: 7, loss:  17393.0938, reconstruct loss:  15380.5898, KL loss:  2012.5049\n",
      "Epoch: 7, loss:  17658.0684, reconstruct loss:  15683.9697, KL loss:  1974.0984\n",
      "Epoch: 7, loss:  17798.1113, reconstruct loss:  15832.5967, KL loss:  1965.5142\n",
      "Epoch: 7, loss:  17447.7168, reconstruct loss:  15529.0303, KL loss:  1918.6870\n",
      "Epoch: 7, loss:  17531.9766, reconstruct loss:  15495.0566, KL loss:  2036.9189\n",
      "Epoch: 7, loss:  17562.9160, reconstruct loss:  15565.8574, KL loss:  1997.0581\n",
      "Epoch: 7, loss:  17483.6445, reconstruct loss:  15470.0693, KL loss:  2013.5754\n",
      "Epoch: 7, loss:  17284.5586, reconstruct loss:  15223.1660, KL loss:  2061.3936\n",
      "Epoch: 7, loss:  17696.2656, reconstruct loss:  15674.3096, KL loss:  2021.9557\n",
      "Epoch: 7, loss:  17106.7715, reconstruct loss:  15085.8047, KL loss:  2020.9670\n",
      "Epoch: 7, loss:  18028.8984, reconstruct loss:  16040.0742, KL loss:  1988.8247\n",
      "Epoch: 7, loss:  16584.6016, reconstruct loss:  14599.0322, KL loss:  1985.5686\n",
      "Epoch: 7, loss:  17010.1211, reconstruct loss:  15058.3301, KL loss:  1951.7910\n",
      "Epoch: 7, loss:  17885.8145, reconstruct loss:  15872.2773, KL loss:  2013.5366\n",
      "Epoch: 7, loss:  17497.5059, reconstruct loss:  15439.8379, KL loss:  2057.6680\n",
      "Epoch: 7, loss:  18536.2988, reconstruct loss:  16556.3223, KL loss:  1979.9757\n",
      "Epoch: 7, loss:  16802.8672, reconstruct loss:  14775.4805, KL loss:  2027.3860\n",
      "Epoch: 7, loss:  17005.7949, reconstruct loss:  14956.4199, KL loss:  2049.3750\n",
      "Epoch: 7, loss:  17947.1816, reconstruct loss:  15946.7471, KL loss:  2000.4338\n",
      "Epoch: 7, loss:  17691.4668, reconstruct loss:  15699.0996, KL loss:  1992.3668\n",
      "Epoch: 7, loss:  18191.2832, reconstruct loss:  16206.4951, KL loss:  1984.7886\n",
      "Epoch: 7, loss:  16905.2520, reconstruct loss:  14903.0596, KL loss:  2002.1921\n",
      "Epoch: 7, loss:  17472.8828, reconstruct loss:  15438.3760, KL loss:  2034.5071\n",
      "Epoch: 8, loss:  17078.8594, reconstruct loss:  15105.5400, KL loss:  1973.3193\n",
      "Epoch: 8, loss:  17032.4473, reconstruct loss:  15091.6865, KL loss:  1940.7615\n",
      "Epoch: 8, loss:  17463.3867, reconstruct loss:  15538.2764, KL loss:  1925.1106\n",
      "Epoch: 8, loss:  17546.8965, reconstruct loss:  15534.5791, KL loss:  2012.3181\n",
      "Epoch: 8, loss:  17040.5762, reconstruct loss:  15053.1777, KL loss:  1987.3984\n",
      "Epoch: 8, loss:  17648.1465, reconstruct loss:  15583.9160, KL loss:  2064.2310\n",
      "Epoch: 8, loss:  17102.2891, reconstruct loss:  15092.3691, KL loss:  2009.9194\n",
      "Epoch: 8, loss:  17299.8516, reconstruct loss:  15256.0078, KL loss:  2043.8438\n",
      "Epoch: 8, loss:  17532.6875, reconstruct loss:  15514.1660, KL loss:  2018.5222\n",
      "Epoch: 8, loss:  17234.5488, reconstruct loss:  15180.4971, KL loss:  2054.0522\n",
      "Epoch: 8, loss:  17379.8164, reconstruct loss:  15347.8887, KL loss:  2031.9281\n",
      "Epoch: 8, loss:  17498.7949, reconstruct loss:  15469.0469, KL loss:  2029.7485\n",
      "Epoch: 8, loss:  17395.4844, reconstruct loss:  15420.9492, KL loss:  1974.5356\n",
      "Epoch: 8, loss:  16652.9668, reconstruct loss:  14658.0488, KL loss:  1994.9177\n",
      "Epoch: 8, loss:  16449.2598, reconstruct loss:  14475.5479, KL loss:  1973.7126\n",
      "Epoch: 8, loss:  17083.0801, reconstruct loss:  15104.7305, KL loss:  1978.3489\n",
      "Epoch: 8, loss:  17465.4160, reconstruct loss:  15450.3184, KL loss:  2015.0973\n",
      "Epoch: 8, loss:  16966.6562, reconstruct loss:  14978.1279, KL loss:  1988.5281\n",
      "Epoch: 8, loss:  16695.5625, reconstruct loss:  14761.0723, KL loss:  1934.4912\n",
      "Epoch: 8, loss:  17617.1211, reconstruct loss:  15637.7861, KL loss:  1979.3359\n",
      "Epoch: 8, loss:  16791.7227, reconstruct loss:  14740.5557, KL loss:  2051.1675\n",
      "Epoch: 8, loss:  17211.1523, reconstruct loss:  15240.7910, KL loss:  1970.3606\n",
      "Epoch: 8, loss:  17242.6074, reconstruct loss:  15195.8340, KL loss:  2046.7736\n",
      "Epoch: 8, loss:  18063.7227, reconstruct loss:  16052.5176, KL loss:  2011.2058\n",
      "Epoch: 8, loss:  16665.1289, reconstruct loss:  14700.5332, KL loss:  1964.5953\n",
      "Epoch: 8, loss:  17230.0859, reconstruct loss:  15160.1621, KL loss:  2069.9229\n",
      "Epoch: 8, loss:  16946.5039, reconstruct loss:  14935.6436, KL loss:  2010.8599\n",
      "Epoch: 8, loss:  16874.5312, reconstruct loss:  14849.7803, KL loss:  2024.7507\n",
      "Epoch: 8, loss:  17538.7461, reconstruct loss:  15510.5996, KL loss:  2028.1475\n",
      "Epoch: 8, loss:  17147.9805, reconstruct loss:  15083.8877, KL loss:  2064.0938\n",
      "Epoch: 8, loss:  17070.1621, reconstruct loss:  15085.2627, KL loss:  1984.8998\n",
      "Epoch: 8, loss:  17045.5039, reconstruct loss:  15030.1367, KL loss:  2015.3669\n",
      "Epoch: 8, loss:  17244.0312, reconstruct loss:  15276.0283, KL loss:  1968.0038\n",
      "Epoch: 8, loss:  18022.3105, reconstruct loss:  16034.9512, KL loss:  1987.3601\n",
      "Epoch: 8, loss:  17226.1113, reconstruct loss:  15228.5674, KL loss:  1997.5443\n",
      "Epoch: 8, loss:  17355.0957, reconstruct loss:  15362.4111, KL loss:  1992.6851\n",
      "Epoch: 8, loss:  17620.0625, reconstruct loss:  15584.7793, KL loss:  2035.2834\n",
      "Epoch: 8, loss:  17797.8594, reconstruct loss:  15758.7705, KL loss:  2039.0881\n",
      "Epoch: 8, loss:  16758.6289, reconstruct loss:  14751.0938, KL loss:  2007.5344\n",
      "Epoch: 8, loss:  16901.6738, reconstruct loss:  14808.2432, KL loss:  2093.4307\n",
      "Epoch: 8, loss:  17457.6602, reconstruct loss:  15445.6689, KL loss:  2011.9916\n",
      "Epoch: 8, loss:  17387.6602, reconstruct loss:  15413.3691, KL loss:  1974.2910\n",
      "Epoch: 8, loss:  17461.0859, reconstruct loss:  15439.0088, KL loss:  2022.0767\n",
      "Epoch: 8, loss:  16894.2383, reconstruct loss:  14920.4551, KL loss:  1973.7842\n",
      "Epoch: 8, loss:  16765.8652, reconstruct loss:  14802.9082, KL loss:  1962.9564\n",
      "Epoch: 8, loss:  17582.7598, reconstruct loss:  15562.5645, KL loss:  2020.1951\n",
      "Epoch: 9, loss:  17457.6465, reconstruct loss:  15437.3691, KL loss:  2020.2767\n",
      "Epoch: 9, loss:  17704.0859, reconstruct loss:  15704.7344, KL loss:  1999.3523\n",
      "Epoch: 9, loss:  17371.3438, reconstruct loss:  15385.2100, KL loss:  1986.1332\n",
      "Epoch: 9, loss:  16779.1504, reconstruct loss:  14765.8984, KL loss:  2013.2515\n",
      "Epoch: 9, loss:  16563.0137, reconstruct loss:  14552.9453, KL loss:  2010.0681\n",
      "Epoch: 9, loss:  16634.5859, reconstruct loss:  14577.8770, KL loss:  2056.7090\n",
      "Epoch: 9, loss:  17640.8047, reconstruct loss:  15588.1465, KL loss:  2052.6582\n",
      "Epoch: 9, loss:  16786.0859, reconstruct loss:  14781.9746, KL loss:  2004.1106\n",
      "Epoch: 9, loss:  15482.6904, reconstruct loss:  13475.7881, KL loss:  2006.9023\n",
      "Epoch: 9, loss:  18009.1543, reconstruct loss:  15956.9922, KL loss:  2052.1621\n",
      "Epoch: 9, loss:  17556.6660, reconstruct loss:  15529.2988, KL loss:  2027.3679\n",
      "Epoch: 9, loss:  17346.5078, reconstruct loss:  15334.0430, KL loss:  2012.4658\n",
      "Epoch: 9, loss:  16850.2051, reconstruct loss:  14879.0117, KL loss:  1971.1941\n",
      "Epoch: 9, loss:  17441.9395, reconstruct loss:  15408.6211, KL loss:  2033.3186\n",
      "Epoch: 9, loss:  17141.9609, reconstruct loss:  15203.2695, KL loss:  1938.6913\n",
      "Epoch: 9, loss:  16581.0293, reconstruct loss:  14553.4600, KL loss:  2027.5686\n",
      "Epoch: 9, loss:  16420.5215, reconstruct loss:  14411.3086, KL loss:  2009.2126\n",
      "Epoch: 9, loss:  16675.2324, reconstruct loss:  14640.1094, KL loss:  2035.1233\n",
      "Epoch: 9, loss:  17921.1445, reconstruct loss:  15885.4580, KL loss:  2035.6868\n",
      "Epoch: 9, loss:  17547.0293, reconstruct loss:  15494.5615, KL loss:  2052.4673\n",
      "Epoch: 9, loss:  17145.8125, reconstruct loss:  15089.3604, KL loss:  2056.4517\n",
      "Epoch: 9, loss:  17285.1172, reconstruct loss:  15272.0625, KL loss:  2013.0553\n",
      "Epoch: 9, loss:  17191.5254, reconstruct loss:  15148.7617, KL loss:  2042.7632\n",
      "Epoch: 9, loss:  16760.3945, reconstruct loss:  14728.9805, KL loss:  2031.4138\n",
      "Epoch: 9, loss:  16896.2891, reconstruct loss:  14784.9766, KL loss:  2111.3127\n",
      "Epoch: 9, loss:  16046.6016, reconstruct loss:  14087.0195, KL loss:  1959.5822\n",
      "Epoch: 9, loss:  17106.1055, reconstruct loss:  15102.5566, KL loss:  2003.5482\n",
      "Epoch: 9, loss:  17481.5137, reconstruct loss:  15462.3398, KL loss:  2019.1733\n",
      "Epoch: 9, loss:  16567.7539, reconstruct loss:  14533.3701, KL loss:  2034.3838\n",
      "Epoch: 9, loss:  17010.6133, reconstruct loss:  15008.0410, KL loss:  2002.5723\n",
      "Epoch: 9, loss:  17001.6855, reconstruct loss:  14937.2109, KL loss:  2064.4751\n",
      "Epoch: 9, loss:  17273.9199, reconstruct loss:  15192.7285, KL loss:  2081.1907\n",
      "Epoch: 9, loss:  17317.3203, reconstruct loss:  15193.6289, KL loss:  2123.6924\n",
      "Epoch: 9, loss:  16423.8105, reconstruct loss:  14373.7646, KL loss:  2050.0459\n",
      "Epoch: 9, loss:  16254.3535, reconstruct loss:  14235.3174, KL loss:  2019.0365\n",
      "Epoch: 9, loss:  16383.1953, reconstruct loss:  14282.4443, KL loss:  2100.7515\n",
      "Epoch: 9, loss:  16463.1973, reconstruct loss:  14476.6279, KL loss:  1986.5688\n",
      "Epoch: 9, loss:  17581.8027, reconstruct loss:  15533.8613, KL loss:  2047.9417\n",
      "Epoch: 9, loss:  16774.2871, reconstruct loss:  14681.6250, KL loss:  2092.6621\n",
      "Epoch: 9, loss:  17072.0215, reconstruct loss:  15044.8301, KL loss:  2027.1910\n",
      "Epoch: 9, loss:  16864.5156, reconstruct loss:  14817.5762, KL loss:  2046.9402\n",
      "Epoch: 9, loss:  17012.1992, reconstruct loss:  14973.3691, KL loss:  2038.8296\n",
      "Epoch: 9, loss:  17437.7598, reconstruct loss:  15349.8340, KL loss:  2087.9255\n",
      "Epoch: 9, loss:  16965.3047, reconstruct loss:  14932.7676, KL loss:  2032.5366\n",
      "Epoch: 9, loss:  16958.5957, reconstruct loss:  14867.0146, KL loss:  2091.5803\n",
      "Epoch: 9, loss:  17279.5566, reconstruct loss:  15214.3086, KL loss:  2065.2485\n",
      "Epoch: 10, loss:  17553.1992, reconstruct loss:  15541.0391, KL loss:  2012.1598\n",
      "Epoch: 10, loss:  17077.3633, reconstruct loss:  14988.5742, KL loss:  2088.7891\n",
      "Epoch: 10, loss:  18168.3613, reconstruct loss:  16115.5371, KL loss:  2052.8237\n",
      "Epoch: 10, loss:  16761.7129, reconstruct loss:  14657.7734, KL loss:  2103.9399\n",
      "Epoch: 10, loss:  16645.9785, reconstruct loss:  14532.1484, KL loss:  2113.8301\n",
      "Epoch: 10, loss:  16815.6094, reconstruct loss:  14741.6836, KL loss:  2073.9263\n",
      "Epoch: 10, loss:  16375.5625, reconstruct loss:  14336.6973, KL loss:  2038.8657\n",
      "Epoch: 10, loss:  17033.4609, reconstruct loss:  14991.5098, KL loss:  2041.9504\n",
      "Epoch: 10, loss:  16566.5859, reconstruct loss:  14486.2314, KL loss:  2080.3547\n",
      "Epoch: 10, loss:  16826.9766, reconstruct loss:  14724.0312, KL loss:  2102.9448\n",
      "Epoch: 10, loss:  16697.6270, reconstruct loss:  14652.0352, KL loss:  2045.5917\n",
      "Epoch: 10, loss:  16911.2695, reconstruct loss:  14784.0117, KL loss:  2127.2568\n",
      "Epoch: 10, loss:  16780.8496, reconstruct loss:  14704.0391, KL loss:  2076.8101\n",
      "Epoch: 10, loss:  16742.8320, reconstruct loss:  14710.1562, KL loss:  2032.6759\n",
      "Epoch: 10, loss:  16545.0488, reconstruct loss:  14431.2598, KL loss:  2113.7883\n",
      "Epoch: 10, loss:  16890.4883, reconstruct loss:  14795.5898, KL loss:  2094.8977\n",
      "Epoch: 10, loss:  16465.1289, reconstruct loss:  14427.9170, KL loss:  2037.2118\n",
      "Epoch: 10, loss:  17231.3594, reconstruct loss:  15104.7520, KL loss:  2126.6064\n",
      "Epoch: 10, loss:  16386.2227, reconstruct loss:  14299.2891, KL loss:  2086.9341\n",
      "Epoch: 10, loss:  16612.3438, reconstruct loss:  14468.2129, KL loss:  2144.1309\n",
      "Epoch: 10, loss:  17254.6328, reconstruct loss:  15214.2285, KL loss:  2040.4041\n",
      "Epoch: 10, loss:  16272.8574, reconstruct loss:  14176.0859, KL loss:  2096.7710\n",
      "Epoch: 10, loss:  17395.8008, reconstruct loss:  15250.0254, KL loss:  2145.7759\n",
      "Epoch: 10, loss:  16418.4277, reconstruct loss:  14300.1445, KL loss:  2118.2825\n",
      "Epoch: 10, loss:  16601.1914, reconstruct loss:  14502.1006, KL loss:  2099.0911\n",
      "Epoch: 10, loss:  16995.0078, reconstruct loss:  14864.1875, KL loss:  2130.8198\n",
      "Epoch: 10, loss:  15647.1143, reconstruct loss:  13618.2764, KL loss:  2028.8383\n",
      "Epoch: 10, loss:  17290.5977, reconstruct loss:  15217.4902, KL loss:  2073.1079\n",
      "Epoch: 10, loss:  16883.3789, reconstruct loss:  14827.4590, KL loss:  2055.9202\n",
      "Epoch: 10, loss:  16631.0996, reconstruct loss:  14544.3672, KL loss:  2086.7332\n",
      "Epoch: 10, loss:  16604.6074, reconstruct loss:  14522.6611, KL loss:  2081.9468\n",
      "Epoch: 10, loss:  16314.9756, reconstruct loss:  14208.0537, KL loss:  2106.9221\n",
      "Epoch: 10, loss:  16786.8281, reconstruct loss:  14669.7715, KL loss:  2117.0562\n",
      "Epoch: 10, loss:  16793.7383, reconstruct loss:  14692.7441, KL loss:  2100.9941\n",
      "Epoch: 10, loss:  17408.9805, reconstruct loss:  15344.2012, KL loss:  2064.7793\n",
      "Epoch: 10, loss:  17178.4199, reconstruct loss:  15054.5410, KL loss:  2123.8784\n",
      "Epoch: 10, loss:  17100.2656, reconstruct loss:  14989.2676, KL loss:  2110.9978\n",
      "Epoch: 10, loss:  17092.6016, reconstruct loss:  14954.2441, KL loss:  2138.3569\n",
      "Epoch: 10, loss:  16538.3770, reconstruct loss:  14540.0117, KL loss:  1998.3647\n",
      "Epoch: 10, loss:  16803.5605, reconstruct loss:  14652.1289, KL loss:  2151.4309\n",
      "Epoch: 10, loss:  16279.0986, reconstruct loss:  14166.1592, KL loss:  2112.9392\n",
      "Epoch: 10, loss:  16882.5488, reconstruct loss:  14732.5488, KL loss:  2149.9995\n",
      "Epoch: 10, loss:  17031.8672, reconstruct loss:  14863.6045, KL loss:  2168.2627\n",
      "Epoch: 10, loss:  16678.4258, reconstruct loss:  14587.3652, KL loss:  2091.0610\n",
      "Epoch: 10, loss:  16790.8223, reconstruct loss:  14745.8535, KL loss:  2044.9684\n",
      "Epoch: 10, loss:  16389.1562, reconstruct loss:  14260.8184, KL loss:  2128.3379\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss = 0\n",
    "  for i, (x, labels) in enumerate(train_loader):\n",
    "    # 予測\n",
    "    x = x.to(device).view(-1, image_size).to(torch.float32)\n",
    "\n",
    "    # class VAE → return x_decoded, mu, log_var, z \n",
    "    x_recon, mu, log_var, z = model(x)\n",
    "    # 損失関数の計算\n",
    "    loss, recon_loss, kl_loss = loss_function(x, x_recon, mu, log_var)\n",
    "\n",
    "    # パラメータの更新\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 損失の表示\n",
    "    if (i+1) % 10 == 0:\n",
    "      print(f'Epoch: {epoch+1}, loss: {loss: 0.4f}, reconstruct loss: {recon_loss: 0.4f}, KL loss: {kl_loss: 0.4f}')\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  z = torch.randn(25, z_dim).to(device)\n",
    "  out = model.decoder(z)\n",
    "out = out.view(-1, 28, 28)\n",
    "out = out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/chqdmqld4h98fpysyglct_4m0000gp/T/ipykernel_2119/697593996.py:7: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "plt.gray()\n",
    "for i in range(25):\n",
    "  idx = divmod(i, 5)\n",
    "  ax[idx].imshow(out[i])\n",
    "  ax[idx].axis('off');   \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7b63737d34f860a632a8143e822850a892e75196c8e7207c138f17d21e5a1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
