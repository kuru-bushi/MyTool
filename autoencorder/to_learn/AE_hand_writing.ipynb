{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE\n",
    "- https://towardsdatascience.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following is an import of PyTorch libraries.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is selected as device!\n"
     ]
    }
   ],
   "source": [
    "# 長田さんコード\n",
    "def select_device():\n",
    "    # “”\"GPU もしくは CPU の選択“”\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda is selected as device!')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        print('mps is selected as device!')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('cpu....f')\n",
    "    return device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Convolutional Variational Autoencoder\n",
    "\"\"\"\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, imgChannels=1, featureDim=32*20*20, zDim=256):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder\n",
    "        self.encConv1 = nn.Conv2d(imgChannels, 16, 5)\n",
    "        self.encConv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.encFC1 = nn.Linear(featureDim, zDim)\n",
    "        self.encFC2 = nn.Linear(featureDim, zDim)\n",
    "\n",
    "        # Initializing the fully-connected layer and 2 convolutional layers for decoder\n",
    "        self.decFC1 = nn.Linear(zDim, featureDim)\n",
    "        self.decConv1 = nn.ConvTranspose2d(32, 16, 5)\n",
    "        self.decConv2 = nn.ConvTranspose2d(16, imgChannels, 5)\n",
    "\n",
    "    def encoder(self, x):\n",
    "\n",
    "        # Input is fed into 2 convolutional layers sequentially\n",
    "        # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)\n",
    "        # Mu and logVar are used for generating middle representation z and KL divergence loss\n",
    "        x = F.relu(self.encConv1(x))\n",
    "        x = F.relu(self.encConv2(x))\n",
    "        x = x.view(-1, 32*20*20)\n",
    "        mu = self.encFC1(x)\n",
    "        logVar = self.encFC2(x)\n",
    "        return mu, logVar\n",
    "\n",
    "    def reparameterize(self, mu, logVar):\n",
    "\n",
    "        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n",
    "        std = torch.exp(logVar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decoder(self, z):\n",
    "\n",
    "        # z is fed back into a fully-connected layers and then into two transpose convolutional layers\n",
    "        # The generated output is the same size of the original input\n",
    "        x = F.relu(self.decFC1(z))\n",
    "        x = x.view(-1, 32, 20, 20)\n",
    "        x = F.relu(self.decConv1(x))\n",
    "        x = torch.sigmoid(self.decConv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n",
    "        # output, mu, and logVar are returned for loss computation\n",
    "        mu, logVar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logVar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab798b0ad74458a1871d612b567f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1b59d86ef64d6ebd3710b6632d480d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c9dedf95d54db0b5b4e298dfa5ac61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ee33dc741445639c72cb8e787f5643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunia/opt/anaconda3/envs/practice2/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 12024.126953125\n",
      "Epoch 1: Loss 10960.306640625\n",
      "Epoch 2: Loss 10877.5078125\n",
      "Epoch 3: Loss 9765.0087890625\n",
      "Epoch 4: Loss 10377.6513671875\n",
      "Epoch 5: Loss 10091.150390625\n",
      "Epoch 6: Loss 9993.4306640625\n",
      "Epoch 7: Loss 10270.1123046875\n",
      "Epoch 8: Loss 10045.04296875\n",
      "Epoch 9: Loss 9544.0927734375\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize Hyperparameters\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create dataloaders to feed data into the neural network\n",
    "Default MNIST dataset is used and standard train/test split is performed\n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                    transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize the network and the Adam optimizer\n",
    "\"\"\"\n",
    "net = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training the network for a given number of epochs\n",
    "The loss after every epoch is printed\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, data in enumerate(train_loader, 0):\n",
    "        imgs, _ = data\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Feeding a batch of images into the network to obtain the output image, mu, and logVar\n",
    "        out, mu, logVar = net(imgs)\n",
    "\n",
    "        # The loss is the BCE loss combined with the KL divergence to ensure the distribution is learnt\n",
    "        kl_divergence = 0.5 * torch.sum(-1 - logVar + mu.pow(2) + logVar.exp())\n",
    "        loss = F.binary_cross_entropy(out, imgs, size_average=False) + kl_divergence\n",
    "\n",
    "        # Backpropagation based on the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {}: Loss {}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following part takes a random image from test loader to feed into the VAE.\n",
    "Both the original image and generated image from the distribution are shown.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in random.sample(list(test_loader), 1):\n",
    "        imgs, _ = data\n",
    "        imgs = imgs.to(device)\n",
    "        img = np.transpose(imgs[0].cpu().numpy(), [1,2,0])\n",
    "        # img = np.array(imgs[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.squeeze(img))\n",
    "        out, mu, logVAR = net(imgs)\n",
    "        outimg = np.transpose(out[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(np.squeeze(outimg))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa, bb = list(test_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
       "            0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
       "            0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
       "            0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
       "            0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
       "            0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
       "            0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "            0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
       "            0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
       "            0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
       "            0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
       "            0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000, 0.0000, 0.0000, 0.0000]]]]),\n",
       " tensor([7]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \n[Clang 11.1.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7b63737d34f860a632a8143e822850a892e75196c8e7207c138f17d21e5a1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
