{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE について書く\n",
    "- https://www.youtube.com/watch?v=g5RECWW-7Wg\n",
    "- 実行できない。。。書写しをミスした？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10725c550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps is selected as device!\n"
     ]
    }
   ],
   "source": [
    "def select_device():\n",
    "    # “”\"GPU もしくは CPU の選択“”\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda is selected as device!')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        print('mps is selected as device!')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('cpu....f')\n",
    "    return device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: x.view(-1)])\n",
    "\n",
    "root = './data_tutorial_VAE'\n",
    "mnist_dataset = datasets.MNIST(root=root, download=True, train=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, device = 'mps'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(device=device)\n",
    "        self.decoder = Decoder(device=device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, var = self.encoder(x)\n",
    "        z = self.reparameterize(mean, var)\n",
    "        y = self.decoder(z)\n",
    "        return y, z\n",
    "\n",
    "    def reparameterize(self, mean, var):\n",
    "        z = mean + torch.sqrt(var) * torch.randn(mean.size()).to(self.device)\n",
    "        return z\n",
    "    \n",
    "    def criterion(self, x):\n",
    "        mean, var = self.encoder(x)\n",
    "        z = self.reparameterize(mean, var)\n",
    "        y = self.decoder(z)\n",
    "        L1 = - torch.mean(torch.sum(x * torch.log(y) + (1 - x) * torch.log(1 - y), dim=1))\n",
    "        L2 = - 1/2 * torch.mean(torch.sum(1 + torch.log(var) - mean**2 - var, dim=1))\n",
    "        L = L1 + L2\n",
    "        return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, device = 'mps'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.l1 = nn.Linear(784, 256)\n",
    "        self.l2 = nn.Linear(256, 128)\n",
    "        self.l_mean = nn.Linear(128, 2)\n",
    "        self.l_var = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.l1(x)\n",
    "        h = torch.relu(h)\n",
    "        h = self.l2(h)\n",
    "        h = torch.relu(h)\n",
    "        mean = self.l_mean(h)\n",
    "        var = self.l_var(h)\n",
    "        var = F.softplus(var)\n",
    "\n",
    "        return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, device='mps'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.l1 = nn.Linear(2, 128)\n",
    "        self.l2 = nn.Linear(128, 256)\n",
    "        self.out = nn.Linear(256, 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.l1(x)\n",
    "        h = torch.relu(h)\n",
    "        h = self.l2(h)\n",
    "        h = torch.relu(h)\n",
    "        h = self.out(h)\n",
    "        y = torch.sigmoid(h)\n",
    "\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VAE(device=device).to(device)\n",
    "criterion = model.criterion\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, t\n",
      "train\n",
      "loss criterion\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "n_epoch = 8\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    loss_mean = 0\n",
    "    for (x, t) in dataloader:\n",
    "        x = x.to(device)\n",
    "        model.train()\n",
    "        print('loss criterion')\n",
    "        loss = criterion(x)\n",
    "        print('zero')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_mean += loss.item()\n",
    "    loss_mean /= len(dataloader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m10\u001b[39m, \u001b[39m2\u001b[39m, device \u001b[39m=\u001b[39m device)\n\u001b[1;32m      3\u001b[0m images \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecoder(z)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = torch.randn(10, 2, device = device)\n",
    "images = model.decoder(z)\n",
    "images = images.view(-1, 28, 28)\n",
    "images = images.squeeze().detach().cpu().numpy()\n",
    "\n",
    "# データの可視化\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(image, cmap='binary_r')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ可視化の前準備\n",
    "img_size = 28\n",
    "n_image = 10\n",
    "image_size_spaced = img_size +2\n",
    "matrix_image = np.zeros((image_size_spaced*n_image, image_size_spaced*n_image))\n",
    "\n",
    "z_1 = torch.linspace(-3, 3, n_image)\n",
    "z_2 = torch.linspace(-3, 3, n_image)\n",
    "\n",
    "for i, z1 in enumerate(z_1):\n",
    "    for j, z2 in enumerate(z_2):\n",
    "        x = torch.tensor([float(z1), float(z2)], device=device)\n",
    "        images = model.decoder(x)\n",
    "        images = images.view(-1, 28, 28)\n",
    "        images = images.squeeze().detach().cpu().numpy()\n",
    "        top = i * image_size_spaced\n",
    "        left = j * image_size_spaced\n",
    "        matrix_image[top : top + img_size, left: left+img_size] = images\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.how(matrix_image.tolist(), cmap=\"Greys_r\")\n",
    "plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7b63737d34f860a632a8143e822850a892e75196c8e7207c138f17d21e5a1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
